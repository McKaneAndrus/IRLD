{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pickle\n",
    "import os\n",
    "import types\n",
    "import random\n",
    "import uuid\n",
    "import math\n",
    "from copy import deepcopy as copy\n",
    "import logging\n",
    "\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "# from gym.envs.robotics import rendering\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.misc import logsumexp\n",
    "import baselines.common.tf_util as U\n",
    "import baselines.her.rollout as roll\n",
    "import baselines.her.experiment.config as config\n",
    "from baselines import logger\n",
    "import pickle as pkl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('savefig', dpi=300)\n",
    "mpl.rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = logging.getLogger('root')\n",
    "# print(logger.hasHandlers())\n",
    "# assert len(logger.handlers) == 1\n",
    "# handler = logger.handlers[0]\n",
    "# handler.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join('data', '5.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create envs, pilot policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_act_dim = 6\n",
    "# n_obs_dim = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ep_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FetchSlide-v1')\n",
    "env.reset()\n",
    "obs, _, _, info = env.step(env.action_space.sample())\n",
    "\n",
    "dims = {'o': obs['observation'].shape[0],\n",
    "    'u': env.action_space.shape[0],\n",
    "    'g': obs['desired_goal'].shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_goals = np.arange(1, 9, 1)\n",
    "n_train_tasks = 10\n",
    "goals = [env.env._sample_goal() for _ in range(n_train_tasks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env_with_goal(env_name, goal):\n",
    "    def make_env():\n",
    "        env = gym.make(env_name)\n",
    "        env.env.goal = goal\n",
    "        return env\n",
    "    return make_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_envs = [env]\n",
    "for goal in goals:\n",
    "    new_env = gym.make('FetchSlide-v1')\n",
    "    new_env.env.goal = goal\n",
    "    train_envs += [new_env]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a DDPG agent with action space 4 x 1.0...\n"
     ]
    }
   ],
   "source": [
    "policy = pkl.load(open(data_dir + \"/slide_policy.pkl\", \"rb\"))\n",
    "# policy = config.configure_existing_ddpg(policy, params=params)\n",
    "# policy._config_replay_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_lander_env(fps=fps, goal=None):\n",
    "#   env = gym.make('LunarLanderContinuous-v2')\n",
    "#   env.unwrapped.goal = goal\n",
    "#   env.action_space = spaces.Discrete(n_act_dim)\n",
    "#   env.unwrapped._step_orig = env.unwrapped.step\n",
    "#   def step(self, action):\n",
    "#     obs, r, done, info = self._step_orig(disc_to_cont(action))\n",
    "#     return obs, r, done, info\n",
    "#   env.unwrapped.step = types.MethodType(step, env.unwrapped)\n",
    "#   env.unwrapped.fps = fps\n",
    "#   return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_newton_envs = [make_lander_env(fps=fast_fps, goal=goal) for goal in train_goals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  def run_ep(policy, env, max_ep_len=max_ep_len, render=False, task_idx=None):\n",
    "#   obs = env.reset()\n",
    "#   done = False\n",
    "#   totalr = 0.\n",
    "#   prev_obs = obs\n",
    "#   rollout = []\n",
    "#   for step_idx in range(max_ep_len+1):\n",
    "#     if done:\n",
    "#       break\n",
    "#     action = policy(obs)\n",
    "#     obs, r, done, info = env.step(action)\n",
    "#     rollout.append((prev_obs, action, r, obs, float(done), task_idx))\n",
    "#     prev_obs = obs\n",
    "#     if render:\n",
    "#       env.render()\n",
    "#     totalr += r\n",
    "#   return rollout\n",
    "\n",
    "T = env._max_episode_steps\n",
    "make_envs = [make_env_with_goal('FetchSlide-v1', goal) for goal in goals]\n",
    "workers = [roll.RolloutWorker(make_env, policy, dims, logger, T, goals=[goals[i]]) for i,make_env in enumerate(make_envs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(4,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space #.contains(np.int64(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit internal dynamics model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_train_rollouts_per_env = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Trying iteration 10 for worker 0 on rollout 0\n",
      "Trying iteration 20 for worker 0 on rollout 0\n",
      "Trying iteration 30 for worker 0 on rollout 0\n",
      "Trying iteration 40 for worker 0 on rollout 0\n",
      "Trying iteration 50 for worker 0 on rollout 0\n",
      "Trying iteration 60 for worker 0 on rollout 0\n",
      "Trying iteration 70 for worker 0 on rollout 0\n",
      "Trying iteration 80 for worker 0 on rollout 0\n",
      "Trying iteration 90 for worker 0 on rollout 0\n",
      "Trying iteration 100 for worker 0 on rollout 0\n",
      "Trying iteration 10 for worker 0 on rollout 2\n",
      "Trying iteration 20 for worker 0 on rollout 2\n",
      "Trying iteration 30 for worker 0 on rollout 2\n",
      "Trying iteration 40 for worker 0 on rollout 2\n",
      "Trying iteration 50 for worker 0 on rollout 2\n",
      "Trying iteration 60 for worker 0 on rollout 2\n",
      "Trying iteration 70 for worker 0 on rollout 2\n",
      "Trying iteration 80 for worker 0 on rollout 2\n",
      "Trying iteration 90 for worker 0 on rollout 2\n",
      "Trying iteration 100 for worker 0 on rollout 2\n",
      "Trying iteration 10 for worker 0 on rollout 3\n",
      "Trying iteration 20 for worker 0 on rollout 3\n",
      "Trying iteration 30 for worker 0 on rollout 3\n",
      "Trying iteration 40 for worker 0 on rollout 3\n",
      "Trying iteration 50 for worker 0 on rollout 3\n",
      "Trying iteration 60 for worker 0 on rollout 3\n",
      "Trying iteration 70 for worker 0 on rollout 3\n",
      "Trying iteration 80 for worker 0 on rollout 3\n",
      "Trying iteration 90 for worker 0 on rollout 3\n",
      "Trying iteration 100 for worker 0 on rollout 3\n",
      "Trying iteration 10 for worker 0 on rollout 4\n",
      "Trying iteration 20 for worker 0 on rollout 4\n",
      "Trying iteration 30 for worker 0 on rollout 4\n",
      "Trying iteration 40 for worker 0 on rollout 4\n",
      "Trying iteration 50 for worker 0 on rollout 4\n",
      "Trying iteration 60 for worker 0 on rollout 4\n",
      "Trying iteration 70 for worker 0 on rollout 4\n",
      "Trying iteration 80 for worker 0 on rollout 4\n",
      "Trying iteration 90 for worker 0 on rollout 4\n",
      "Trying iteration 100 for worker 0 on rollout 4\n",
      "Trying iteration 10 for worker 0 on rollout 6\n",
      "Trying iteration 20 for worker 0 on rollout 6\n",
      "Trying iteration 30 for worker 0 on rollout 6\n",
      "Trying iteration 40 for worker 0 on rollout 6\n",
      "Trying iteration 50 for worker 0 on rollout 6\n",
      "Trying iteration 60 for worker 0 on rollout 6\n",
      "Trying iteration 70 for worker 0 on rollout 6\n",
      "Trying iteration 80 for worker 0 on rollout 6\n",
      "Trying iteration 90 for worker 0 on rollout 6\n",
      "Trying iteration 100 for worker 0 on rollout 6\n",
      "Trying iteration 10 for worker 0 on rollout 7\n",
      "Trying iteration 20 for worker 0 on rollout 7\n",
      "Trying iteration 30 for worker 0 on rollout 7\n",
      "Trying iteration 40 for worker 0 on rollout 7\n",
      "Trying iteration 50 for worker 0 on rollout 7\n",
      "Trying iteration 60 for worker 0 on rollout 7\n",
      "Trying iteration 70 for worker 0 on rollout 7\n",
      "Trying iteration 80 for worker 0 on rollout 7\n",
      "Trying iteration 90 for worker 0 on rollout 7\n",
      "Trying iteration 100 for worker 0 on rollout 7\n",
      "Trying iteration 10 for worker 0 on rollout 8\n",
      "Trying iteration 20 for worker 0 on rollout 8\n",
      "Trying iteration 10 for worker 0 on rollout 9\n",
      "Trying iteration 20 for worker 0 on rollout 9\n",
      "Trying iteration 30 for worker 0 on rollout 9\n",
      "Trying iteration 40 for worker 0 on rollout 9\n",
      "Trying iteration 50 for worker 0 on rollout 9\n",
      "1\n",
      "Trying iteration 10 for worker 1 on rollout 0\n",
      "Trying iteration 10 for worker 1 on rollout 1\n",
      "Trying iteration 20 for worker 1 on rollout 1\n",
      "Trying iteration 30 for worker 1 on rollout 1\n",
      "Trying iteration 40 for worker 1 on rollout 1\n",
      "Trying iteration 50 for worker 1 on rollout 1\n",
      "Trying iteration 60 for worker 1 on rollout 1\n",
      "Trying iteration 70 for worker 1 on rollout 1\n",
      "Trying iteration 80 for worker 1 on rollout 1\n",
      "Trying iteration 90 for worker 1 on rollout 1\n",
      "Trying iteration 100 for worker 1 on rollout 1\n",
      "Trying iteration 10 for worker 1 on rollout 3\n",
      "Trying iteration 20 for worker 1 on rollout 3\n",
      "Trying iteration 10 for worker 1 on rollout 4\n",
      "Trying iteration 20 for worker 1 on rollout 4\n",
      "Trying iteration 30 for worker 1 on rollout 4\n",
      "Trying iteration 10 for worker 1 on rollout 5\n",
      "Trying iteration 20 for worker 1 on rollout 5\n",
      "Trying iteration 30 for worker 1 on rollout 5\n",
      "Trying iteration 10 for worker 1 on rollout 6\n",
      "Trying iteration 20 for worker 1 on rollout 6\n",
      "Trying iteration 30 for worker 1 on rollout 6\n",
      "Trying iteration 40 for worker 1 on rollout 6\n",
      "Trying iteration 10 for worker 1 on rollout 7\n",
      "Trying iteration 20 for worker 1 on rollout 7\n",
      "Trying iteration 30 for worker 1 on rollout 7\n",
      "Trying iteration 10 for worker 1 on rollout 8\n",
      "Trying iteration 20 for worker 1 on rollout 8\n",
      "Trying iteration 30 for worker 1 on rollout 8\n",
      "Trying iteration 40 for worker 1 on rollout 8\n",
      "2\n",
      "Trying iteration 10 for worker 2 on rollout 0\n",
      "Trying iteration 10 for worker 2 on rollout 1\n",
      "Trying iteration 20 for worker 2 on rollout 1\n",
      "Trying iteration 10 for worker 2 on rollout 2\n",
      "Trying iteration 20 for worker 2 on rollout 2\n",
      "Trying iteration 30 for worker 2 on rollout 2\n",
      "Trying iteration 10 for worker 2 on rollout 4\n",
      "Trying iteration 20 for worker 2 on rollout 4\n",
      "Trying iteration 30 for worker 2 on rollout 4\n",
      "Trying iteration 10 for worker 2 on rollout 5\n",
      "Trying iteration 20 for worker 2 on rollout 5\n",
      "Trying iteration 30 for worker 2 on rollout 5\n",
      "Trying iteration 40 for worker 2 on rollout 5\n",
      "Trying iteration 50 for worker 2 on rollout 5\n",
      "Trying iteration 60 for worker 2 on rollout 5\n",
      "Trying iteration 10 for worker 2 on rollout 6\n",
      "Trying iteration 20 for worker 2 on rollout 6\n",
      "Trying iteration 30 for worker 2 on rollout 6\n",
      "Trying iteration 40 for worker 2 on rollout 6\n",
      "Trying iteration 10 for worker 2 on rollout 7\n",
      "Trying iteration 20 for worker 2 on rollout 7\n",
      "Trying iteration 30 for worker 2 on rollout 7\n",
      "Trying iteration 10 for worker 2 on rollout 8\n",
      "Trying iteration 20 for worker 2 on rollout 8\n",
      "Trying iteration 30 for worker 2 on rollout 8\n",
      "Trying iteration 40 for worker 2 on rollout 8\n",
      "Trying iteration 50 for worker 2 on rollout 8\n",
      "Trying iteration 60 for worker 2 on rollout 8\n",
      "Trying iteration 70 for worker 2 on rollout 8\n",
      "Trying iteration 10 for worker 2 on rollout 9\n",
      "Trying iteration 20 for worker 2 on rollout 9\n",
      "Trying iteration 30 for worker 2 on rollout 9\n",
      "Trying iteration 40 for worker 2 on rollout 9\n",
      "Trying iteration 50 for worker 2 on rollout 9\n",
      "Trying iteration 60 for worker 2 on rollout 9\n",
      "3\n",
      "Trying iteration 10 for worker 3 on rollout 0\n",
      "Trying iteration 20 for worker 3 on rollout 0\n",
      "Trying iteration 30 for worker 3 on rollout 0\n",
      "Trying iteration 40 for worker 3 on rollout 0\n",
      "Trying iteration 50 for worker 3 on rollout 0\n",
      "Trying iteration 60 for worker 3 on rollout 0\n",
      "Trying iteration 70 for worker 3 on rollout 0\n",
      "Trying iteration 80 for worker 3 on rollout 0\n",
      "Trying iteration 90 for worker 3 on rollout 0\n",
      "Trying iteration 10 for worker 3 on rollout 3\n",
      "Trying iteration 20 for worker 3 on rollout 3\n",
      "Trying iteration 30 for worker 3 on rollout 3\n",
      "Trying iteration 40 for worker 3 on rollout 3\n",
      "Trying iteration 50 for worker 3 on rollout 3\n",
      "Trying iteration 60 for worker 3 on rollout 3\n",
      "Trying iteration 70 for worker 3 on rollout 3\n",
      "Trying iteration 10 for worker 3 on rollout 4\n",
      "Trying iteration 20 for worker 3 on rollout 4\n",
      "Trying iteration 30 for worker 3 on rollout 4\n",
      "Trying iteration 40 for worker 3 on rollout 4\n",
      "Trying iteration 50 for worker 3 on rollout 4\n",
      "Trying iteration 60 for worker 3 on rollout 4\n",
      "Trying iteration 70 for worker 3 on rollout 4\n",
      "Trying iteration 80 for worker 3 on rollout 4\n",
      "Trying iteration 90 for worker 3 on rollout 4\n",
      "Trying iteration 100 for worker 3 on rollout 4\n",
      "Trying iteration 10 for worker 3 on rollout 6\n",
      "Trying iteration 20 for worker 3 on rollout 6\n",
      "Trying iteration 30 for worker 3 on rollout 6\n",
      "Trying iteration 40 for worker 3 on rollout 6\n",
      "Trying iteration 50 for worker 3 on rollout 6\n",
      "Trying iteration 60 for worker 3 on rollout 6\n",
      "Trying iteration 70 for worker 3 on rollout 6\n",
      "Trying iteration 80 for worker 3 on rollout 6\n",
      "Trying iteration 90 for worker 3 on rollout 6\n",
      "Trying iteration 100 for worker 3 on rollout 6\n",
      "Trying iteration 10 for worker 3 on rollout 7\n",
      "Trying iteration 20 for worker 3 on rollout 7\n",
      "Trying iteration 30 for worker 3 on rollout 7\n",
      "Trying iteration 40 for worker 3 on rollout 7\n",
      "Trying iteration 50 for worker 3 on rollout 7\n",
      "Trying iteration 60 for worker 3 on rollout 7\n",
      "Trying iteration 70 for worker 3 on rollout 7\n",
      "Trying iteration 80 for worker 3 on rollout 7\n",
      "Trying iteration 90 for worker 3 on rollout 7\n",
      "Trying iteration 100 for worker 3 on rollout 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying iteration 10 for worker 3 on rollout 8\n",
      "Trying iteration 20 for worker 3 on rollout 8\n",
      "4\n",
      "Trying iteration 10 for worker 4 on rollout 0\n",
      "Trying iteration 10 for worker 4 on rollout 3\n",
      "Trying iteration 10 for worker 4 on rollout 4\n",
      "Trying iteration 20 for worker 4 on rollout 4\n",
      "Trying iteration 30 for worker 4 on rollout 4\n",
      "Trying iteration 40 for worker 4 on rollout 4\n",
      "Trying iteration 50 for worker 4 on rollout 4\n",
      "Trying iteration 60 for worker 4 on rollout 4\n",
      "Trying iteration 10 for worker 4 on rollout 5\n",
      "Trying iteration 10 for worker 4 on rollout 6\n",
      "Trying iteration 20 for worker 4 on rollout 6\n",
      "Trying iteration 10 for worker 4 on rollout 8\n",
      "Trying iteration 20 for worker 4 on rollout 8\n",
      "Trying iteration 30 for worker 4 on rollout 8\n",
      "Trying iteration 40 for worker 4 on rollout 8\n",
      "Trying iteration 50 for worker 4 on rollout 8\n",
      "Trying iteration 60 for worker 4 on rollout 8\n",
      "Trying iteration 70 for worker 4 on rollout 8\n",
      "Trying iteration 80 for worker 4 on rollout 8\n",
      "Trying iteration 90 for worker 4 on rollout 8\n",
      "Trying iteration 100 for worker 4 on rollout 8\n",
      "Trying iteration 10 for worker 4 on rollout 9\n",
      "5\n",
      "Trying iteration 10 for worker 5 on rollout 0\n",
      "Trying iteration 20 for worker 5 on rollout 0\n",
      "Trying iteration 30 for worker 5 on rollout 0\n",
      "Trying iteration 40 for worker 5 on rollout 0\n",
      "Trying iteration 50 for worker 5 on rollout 0\n",
      "Trying iteration 60 for worker 5 on rollout 0\n",
      "Trying iteration 10 for worker 5 on rollout 1\n",
      "Trying iteration 20 for worker 5 on rollout 1\n",
      "Trying iteration 30 for worker 5 on rollout 1\n",
      "Trying iteration 40 for worker 5 on rollout 1\n",
      "Trying iteration 50 for worker 5 on rollout 1\n",
      "Trying iteration 60 for worker 5 on rollout 1\n",
      "Trying iteration 70 for worker 5 on rollout 1\n",
      "Trying iteration 80 for worker 5 on rollout 1\n",
      "Trying iteration 90 for worker 5 on rollout 1\n",
      "Trying iteration 100 for worker 5 on rollout 1\n",
      "Trying iteration 10 for worker 5 on rollout 3\n",
      "Trying iteration 10 for worker 5 on rollout 4\n",
      "Trying iteration 20 for worker 5 on rollout 4\n",
      "Trying iteration 30 for worker 5 on rollout 4\n",
      "Trying iteration 40 for worker 5 on rollout 4\n",
      "Trying iteration 10 for worker 5 on rollout 5\n",
      "Trying iteration 20 for worker 5 on rollout 5\n",
      "Trying iteration 30 for worker 5 on rollout 5\n",
      "Trying iteration 40 for worker 5 on rollout 5\n",
      "Trying iteration 50 for worker 5 on rollout 5\n",
      "Trying iteration 60 for worker 5 on rollout 5\n",
      "Trying iteration 70 for worker 5 on rollout 5\n",
      "Trying iteration 80 for worker 5 on rollout 5\n",
      "Trying iteration 90 for worker 5 on rollout 5\n",
      "Trying iteration 100 for worker 5 on rollout 5\n",
      "Trying iteration 10 for worker 5 on rollout 6\n",
      "Trying iteration 20 for worker 5 on rollout 6\n",
      "Trying iteration 30 for worker 5 on rollout 6\n",
      "Trying iteration 40 for worker 5 on rollout 6\n",
      "Trying iteration 50 for worker 5 on rollout 6\n",
      "Trying iteration 60 for worker 5 on rollout 6\n",
      "Trying iteration 70 for worker 5 on rollout 6\n",
      "Trying iteration 80 for worker 5 on rollout 6\n",
      "Trying iteration 90 for worker 5 on rollout 6\n",
      "Trying iteration 100 for worker 5 on rollout 6\n",
      "Trying iteration 10 for worker 5 on rollout 7\n",
      "Trying iteration 20 for worker 5 on rollout 7\n",
      "Trying iteration 30 for worker 5 on rollout 7\n",
      "Trying iteration 40 for worker 5 on rollout 7\n",
      "Trying iteration 50 for worker 5 on rollout 7\n",
      "Trying iteration 60 for worker 5 on rollout 7\n",
      "Trying iteration 70 for worker 5 on rollout 7\n",
      "Trying iteration 80 for worker 5 on rollout 7\n",
      "Trying iteration 90 for worker 5 on rollout 7\n",
      "Trying iteration 100 for worker 5 on rollout 7\n",
      "6\n",
      "Trying iteration 10 for worker 6 on rollout 1\n",
      "Trying iteration 10 for worker 6 on rollout 2\n",
      "Trying iteration 10 for worker 6 on rollout 4\n",
      "Trying iteration 20 for worker 6 on rollout 4\n",
      "Trying iteration 30 for worker 6 on rollout 4\n",
      "Trying iteration 10 for worker 6 on rollout 5\n",
      "Trying iteration 20 for worker 6 on rollout 5\n",
      "Trying iteration 30 for worker 6 on rollout 5\n",
      "Trying iteration 10 for worker 6 on rollout 6\n",
      "Trying iteration 20 for worker 6 on rollout 6\n",
      "Trying iteration 10 for worker 6 on rollout 8\n",
      "Trying iteration 20 for worker 6 on rollout 8\n",
      "Trying iteration 30 for worker 6 on rollout 8\n",
      "Trying iteration 40 for worker 6 on rollout 8\n",
      "Trying iteration 50 for worker 6 on rollout 8\n",
      "Trying iteration 60 for worker 6 on rollout 8\n",
      "Trying iteration 70 for worker 6 on rollout 8\n",
      "Trying iteration 10 for worker 6 on rollout 9\n",
      "7\n",
      "Trying iteration 10 for worker 7 on rollout 0\n",
      "Trying iteration 10 for worker 7 on rollout 1\n",
      "Trying iteration 20 for worker 7 on rollout 1\n",
      "Trying iteration 30 for worker 7 on rollout 1\n",
      "Trying iteration 40 for worker 7 on rollout 1\n",
      "Trying iteration 50 for worker 7 on rollout 1\n",
      "Trying iteration 60 for worker 7 on rollout 1\n",
      "Trying iteration 70 for worker 7 on rollout 1\n",
      "Trying iteration 80 for worker 7 on rollout 1\n",
      "Trying iteration 90 for worker 7 on rollout 1\n",
      "Trying iteration 100 for worker 7 on rollout 1\n",
      "Trying iteration 10 for worker 7 on rollout 2\n",
      "Trying iteration 20 for worker 7 on rollout 2\n",
      "Trying iteration 30 for worker 7 on rollout 2\n",
      "Trying iteration 40 for worker 7 on rollout 2\n",
      "Trying iteration 50 for worker 7 on rollout 2\n",
      "Trying iteration 60 for worker 7 on rollout 2\n",
      "Trying iteration 70 for worker 7 on rollout 2\n",
      "Trying iteration 80 for worker 7 on rollout 2\n",
      "Trying iteration 90 for worker 7 on rollout 2\n",
      "Trying iteration 100 for worker 7 on rollout 2\n",
      "Trying iteration 10 for worker 7 on rollout 3\n",
      "Trying iteration 20 for worker 7 on rollout 3\n",
      "Trying iteration 30 for worker 7 on rollout 3\n",
      "Trying iteration 40 for worker 7 on rollout 3\n",
      "Trying iteration 50 for worker 7 on rollout 3\n",
      "Trying iteration 60 for worker 7 on rollout 3\n",
      "Trying iteration 70 for worker 7 on rollout 3\n",
      "Trying iteration 80 for worker 7 on rollout 3\n",
      "Trying iteration 90 for worker 7 on rollout 3\n",
      "Trying iteration 100 for worker 7 on rollout 3\n",
      "Trying iteration 10 for worker 7 on rollout 5\n",
      "Trying iteration 20 for worker 7 on rollout 5\n",
      "Trying iteration 30 for worker 7 on rollout 5\n",
      "Trying iteration 40 for worker 7 on rollout 5\n",
      "Trying iteration 50 for worker 7 on rollout 5\n",
      "Trying iteration 60 for worker 7 on rollout 5\n",
      "Trying iteration 70 for worker 7 on rollout 5\n",
      "Trying iteration 80 for worker 7 on rollout 5\n",
      "Trying iteration 10 for worker 7 on rollout 6\n",
      "Trying iteration 20 for worker 7 on rollout 6\n",
      "Trying iteration 30 for worker 7 on rollout 6\n",
      "Trying iteration 40 for worker 7 on rollout 6\n",
      "Trying iteration 50 for worker 7 on rollout 6\n",
      "Trying iteration 60 for worker 7 on rollout 6\n",
      "Trying iteration 70 for worker 7 on rollout 6\n",
      "Trying iteration 80 for worker 7 on rollout 6\n",
      "Trying iteration 90 for worker 7 on rollout 6\n",
      "Trying iteration 10 for worker 7 on rollout 7\n",
      "Trying iteration 20 for worker 7 on rollout 7\n",
      "Trying iteration 30 for worker 7 on rollout 7\n",
      "Trying iteration 40 for worker 7 on rollout 7\n",
      "Trying iteration 50 for worker 7 on rollout 7\n",
      "Trying iteration 60 for worker 7 on rollout 7\n",
      "Trying iteration 70 for worker 7 on rollout 7\n",
      "Trying iteration 80 for worker 7 on rollout 7\n",
      "Trying iteration 90 for worker 7 on rollout 7\n",
      "Trying iteration 100 for worker 7 on rollout 7\n",
      "Trying iteration 10 for worker 7 on rollout 8\n",
      "Trying iteration 20 for worker 7 on rollout 8\n",
      "Trying iteration 30 for worker 7 on rollout 8\n",
      "Trying iteration 40 for worker 7 on rollout 8\n",
      "Trying iteration 50 for worker 7 on rollout 8\n",
      "Trying iteration 60 for worker 7 on rollout 8\n",
      "Trying iteration 70 for worker 7 on rollout 8\n",
      "Trying iteration 80 for worker 7 on rollout 8\n",
      "Trying iteration 90 for worker 7 on rollout 8\n",
      "Trying iteration 10 for worker 7 on rollout 9\n",
      "Trying iteration 20 for worker 7 on rollout 9\n",
      "Trying iteration 30 for worker 7 on rollout 9\n",
      "Trying iteration 40 for worker 7 on rollout 9\n",
      "Trying iteration 50 for worker 7 on rollout 9\n",
      "Trying iteration 60 for worker 7 on rollout 9\n",
      "Trying iteration 70 for worker 7 on rollout 9\n",
      "Trying iteration 80 for worker 7 on rollout 9\n",
      "Trying iteration 90 for worker 7 on rollout 9\n",
      "Trying iteration 100 for worker 7 on rollout 9\n",
      "8\n",
      "Trying iteration 10 for worker 8 on rollout 0\n",
      "Trying iteration 20 for worker 8 on rollout 0\n",
      "Trying iteration 30 for worker 8 on rollout 0\n",
      "Trying iteration 40 for worker 8 on rollout 0\n",
      "Trying iteration 50 for worker 8 on rollout 0\n",
      "Trying iteration 10 for worker 8 on rollout 1\n",
      "Trying iteration 20 for worker 8 on rollout 1\n",
      "Trying iteration 30 for worker 8 on rollout 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying iteration 40 for worker 8 on rollout 1\n",
      "Trying iteration 10 for worker 8 on rollout 3\n",
      "Trying iteration 10 for worker 8 on rollout 4\n",
      "Trying iteration 10 for worker 8 on rollout 6\n",
      "Trying iteration 10 for worker 8 on rollout 7\n",
      "Trying iteration 20 for worker 8 on rollout 7\n",
      "Trying iteration 30 for worker 8 on rollout 7\n",
      "Trying iteration 40 for worker 8 on rollout 7\n",
      "Trying iteration 50 for worker 8 on rollout 7\n",
      "Trying iteration 10 for worker 8 on rollout 8\n",
      "9\n",
      "Trying iteration 10 for worker 9 on rollout 0\n",
      "Trying iteration 20 for worker 9 on rollout 0\n",
      "Trying iteration 30 for worker 9 on rollout 0\n",
      "Trying iteration 40 for worker 9 on rollout 0\n",
      "Trying iteration 50 for worker 9 on rollout 0\n",
      "Trying iteration 60 for worker 9 on rollout 0\n",
      "Trying iteration 10 for worker 9 on rollout 1\n",
      "Trying iteration 20 for worker 9 on rollout 1\n",
      "Trying iteration 30 for worker 9 on rollout 1\n",
      "Trying iteration 40 for worker 9 on rollout 1\n",
      "Trying iteration 10 for worker 9 on rollout 2\n",
      "Trying iteration 20 for worker 9 on rollout 2\n",
      "Trying iteration 30 for worker 9 on rollout 2\n",
      "Trying iteration 40 for worker 9 on rollout 2\n",
      "Trying iteration 50 for worker 9 on rollout 2\n",
      "Trying iteration 10 for worker 9 on rollout 3\n",
      "Trying iteration 20 for worker 9 on rollout 3\n",
      "Trying iteration 30 for worker 9 on rollout 3\n",
      "Trying iteration 10 for worker 9 on rollout 4\n",
      "Trying iteration 20 for worker 9 on rollout 4\n",
      "Trying iteration 30 for worker 9 on rollout 4\n",
      "Trying iteration 40 for worker 9 on rollout 4\n",
      "Trying iteration 50 for worker 9 on rollout 4\n",
      "Trying iteration 10 for worker 9 on rollout 5\n",
      "Trying iteration 20 for worker 9 on rollout 5\n",
      "Trying iteration 30 for worker 9 on rollout 5\n",
      "Trying iteration 10 for worker 9 on rollout 6\n",
      "Trying iteration 20 for worker 9 on rollout 6\n",
      "Trying iteration 30 for worker 9 on rollout 6\n",
      "Trying iteration 10 for worker 9 on rollout 7\n",
      "Trying iteration 20 for worker 9 on rollout 7\n",
      "Trying iteration 30 for worker 9 on rollout 7\n",
      "Trying iteration 10 for worker 9 on rollout 8\n",
      "Trying iteration 20 for worker 9 on rollout 8\n",
      "Trying iteration 30 for worker 9 on rollout 8\n",
      "Trying iteration 40 for worker 9 on rollout 8\n",
      "Trying iteration 50 for worker 9 on rollout 8\n",
      "Trying iteration 10 for worker 9 on rollout 9\n",
      "Trying iteration 20 for worker 9 on rollout 9\n",
      "Trying iteration 30 for worker 9 on rollout 9\n"
     ]
    }
   ],
   "source": [
    "# Don't have best expert, ensure all demos are successes\n",
    "\n",
    "demo_rollouts = []\n",
    "max_attempt = 100\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "    worker_demos = []\n",
    "    print(i)\n",
    "    for _ in range(n_train_rollouts_per_env):\n",
    "        rollout, success = worker.generate_rollouts(True)\n",
    "        attempt = 0\n",
    "        while not success.any():\n",
    "            rollout, success = worker.generate_rollouts(True)\n",
    "            attempt += 1\n",
    "#             print(worker.envs[0].env.goal)\n",
    "            if attempt % 10 == 0:\n",
    "                print(\"Trying iteration {} for worker {} on rollout {}\".format(attempt, i, _))\n",
    "            if attempt > max_attempt:\n",
    "                rollout = None\n",
    "                break\n",
    "        worker_demos += [rollout]\n",
    "    demo_rollouts += [worker_demos]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually select rollout for now\n",
    "n_obs_dim = demo_rollouts[0][1]['o'][0].shape[1]\n",
    "n_act_dim = demo_rollouts[0][1]['u'][0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_rollouts[0][1]['ag'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_rollouts_path = os.path.join(data_dir, 'pilot_policy_demo_rollouts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'pilot_policy_demo_rollouts.pkl'), 'wb') as f:\n",
    "  pickle.dump(demo_rollouts, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(demo_rollouts_path, 'rb') as f:\n",
    "#   demo_rollouts = pickle.load(f)\n",
    "\n",
    "# demo_rollouts = demo_rollouts[:len(train_goals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(\n",
    "    input_placeholder,\n",
    "    output_size,\n",
    "    scope,\n",
    "    n_layers=1,\n",
    "    size=256,\n",
    "    activation=tf.nn.relu,\n",
    "    output_activation=None,\n",
    "    reuse=False\n",
    "  ):\n",
    "  out = input_placeholder\n",
    "  with tf.variable_scope(scope, reuse=reuse):\n",
    "    for _ in range(n_layers):\n",
    "      out = tf.layers.dense(out, size, activation=activation)\n",
    "    out = tf.layers.dense(out, output_size, activation=output_activation)\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vectorize_rollouts(rollouts):\n",
    "  obs = [[] for _ in range(n_train_tasks)]\n",
    "  actions = [[] for _ in range(n_train_tasks)]\n",
    "  next_obs = [[] for _ in range(n_train_tasks)]\n",
    "  ach_goals = [[] for _ in range(n_train_tasks)]\n",
    "  goals = [[] for _ in range(n_train_tasks)]\n",
    "  for task_idx, task_rollouts in enumerate(rollouts):\n",
    "    for task_rollout in task_rollouts:\n",
    "        if task_rollout is None:\n",
    "            continue\n",
    "        more_obs, more_actions, more_ags = task_rollout['o'][0], task_rollout['u'][0], task_rollout['ag'][0]\n",
    "        more_goals = task_rollout['g'][0]\n",
    "        more_next_obs = more_obs[1:].copy()\n",
    "        more_obs = more_obs[:-1]\n",
    "        obs[task_idx] += [more_obs]\n",
    "        actions[task_idx] += [more_actions]\n",
    "        next_obs[task_idx] += [more_next_obs]\n",
    "        ach_goals[task_idx] += [more_ags[1:]]\n",
    "        goals[task_idx] += [more_goals]\n",
    "\n",
    "  min_ro = len(min(obs, key=lambda o: len(o)))\n",
    "  obs = np.array([np.vstack(obs_set[:min_ro]) for obs_set in obs])\n",
    "  actions = np.array([np.vstack(action_set[:min_ro]) for action_set in actions])\n",
    "  next_obs = np.array([np.vstack(obs_set[:min_ro]) for obs_set in next_obs])\n",
    "  ach_goals = np.array([np.vstack(goal_set[:min_ro]) for goal_set in ach_goals])\n",
    "  goals = np.array([np.vstack(goal_set[:min_ro]) for goal_set in goals])\n",
    "\n",
    "  return obs, actions, next_obs, ach_goals, goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_obs = None\n",
    "demo_actions = None\n",
    "demo_act_feats = None\n",
    "demo_next_obs = None\n",
    "demo_task_idxes = None\n",
    "train_demo_example_idxes = None\n",
    "val_demo_batch = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_demo_rollouts(demo_rollouts):\n",
    "  global demo_obs\n",
    "  global demo_actions\n",
    "  global demo_act_feats\n",
    "  global demo_next_obs\n",
    "  global demo_task_idxes\n",
    "  global train_demo_example_idxes\n",
    "  global val_demo_batch\n",
    "\n",
    "  \n",
    "  demo_obs, demo_actions, demo_next_obs, demo_ach_goals, demo_goals = vectorize_rollouts(demo_rollouts)\n",
    "  demo_example_idxes = list(range(demo_obs.shape[1]))\n",
    "  \n",
    "  random.shuffle(demo_example_idxes)\n",
    "  n_train_demo_examples = int(0.9 * len(demo_example_idxes))\n",
    "  train_demo_example_idxes = demo_example_idxes[:n_train_demo_examples]\n",
    "  val_demo_example_idxes = demo_example_idxes[n_train_demo_examples:]\n",
    "  val_demo_batch = (demo_obs[:, val_demo_example_idxes], demo_actions[:, val_demo_example_idxes],\n",
    "        demo_next_obs[:, val_demo_example_idxes], demo_ach_goals[:, val_demo_example_idxes], \n",
    "        demo_goals[:, val_demo_example_idxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(250, 3), (250, 3), (250, 3), (250, 3), (250, 3), (250, 3), (250, 3), (250, 3), (250, 3), (250, 3)]\n"
     ]
    }
   ],
   "source": [
    "process_demo_rollouts(demo_rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 250, 25)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(size):\n",
    "  idxes = random.sample(train_demo_example_idxes, size)\n",
    "  demo_batch = demo_obs[:, idxes], demo_actions[:, idxes], demo_act_feats[:, idxes], demo_next_obs[:, idxes]\n",
    "  return demo_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "iterations = 100000\n",
    "learning_rate = 1e-3\n",
    "batch_size = 512 // n_train_tasks\n",
    "sq_td_err_penalty = 1e-3\n",
    "trans_err_penalty = 1e0\n",
    "\n",
    "\n",
    "q_n_layers = 1\n",
    "q_layer_size = 32\n",
    "q_activation = tf.nn.relu\n",
    "q_output_activation = None\n",
    "\n",
    "invdyn_n_layers = 1\n",
    "invdyn_layer_size = 32\n",
    "invdyn_activation = tf.nn.relu\n",
    "invdyn_output_activation = None\n",
    "\n",
    "\n",
    "constraint_sampling_freq = 100000\n",
    "constraint_batch_size = batch_size\n",
    "n_constraint_rollouts_per_env = 100\n",
    "\n",
    "val_update_freq = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# im_scope =  str(uuid.uuid4())\n",
    "# q_scope = str(uuid.uuid4())\n",
    "# invdyn_scope = str(uuid.uuid4())\n",
    "\n",
    "# with open(os.path.join(data_dir, 'im_scope.pkl'), 'wb') as f:\n",
    "#   pickle.dump(im_scope, f)\n",
    "\n",
    "# with open(os.path.join(data_dir, 'q_scope.pkl'), 'wb') as f:\n",
    "#   pickle.dump(q_scope, f)\n",
    "\n",
    "# with open(os.path.join(data_dir, 'invdyn_scope.pkl'), 'wb') as f:\n",
    "#   pickle.dump(invdyn_scope, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'im_scope.pkl'), 'rb') as f:\n",
    "  im_scope = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(data_dir, 'q_scope.pkl'), 'rb') as f:\n",
    "  q_scope = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(data_dir, 'invdyn_scope.pkl'), 'rb') as f:\n",
    "  invdyn_scope = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo_obs_t_ph = tf.placeholder(tf.float32, [n_train_tasks, None, n_obs_dim], name=\"dot\")\n",
    "demo_act_t_ph = tf.placeholder(tf.int32, [n_train_tasks, None, n_act_dim], name=\"dat\")\n",
    "demo_next_obs_t_ph = tf.placeholder(tf.float32, [n_train_tasks, None, n_obs_dim], name=\"dnot\")\n",
    "demo_batch_size_ph = tf.placeholder(tf.int32, name=\"dbs\")\n",
    "\n",
    "sample_act_t_ph = tf.placeholder(tf.int32, [n_train_tasks, None, n_act_dim, n_act_samples], name=\"sat\")\n",
    "\n",
    "\n",
    "constraint_obs_t_ph = tf.placeholder(tf.float32, [n_train_tasks, None, n_obs_dim], name=\"cot\")\n",
    "constraint_act_t_ph = tf.placeholder(tf.float32, [n_train_tasks, None, n_act_dim], name=\"cat\")\n",
    "constraint_rew_t_ph = tf.placeholder(tf.float32, [n_train_tasks, None], name=\"crt\")\n",
    "constraint_batch_size_ph = tf.placeholder(tf.int32, name=\"cbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo_batch_idxes = tf.reshape(\n",
    "  tf.range(0, demo_batch_size_ph, 1), \n",
    "  [demo_batch_size_ph, 1])\n",
    "\n",
    "extract_task = lambda x, i: tf.squeeze(tf.gather(x, tf.convert_to_tensor(\n",
    "  [i], dtype=tf.int32)), axis=[0]) \n",
    "\n",
    "demo_q_t = tf.stack([tf.gather_nd(\n",
    "  build_mlp(\n",
    "    tf.concat((extract_task(demo_obs_t_ph, train_task_idx),  extract_task(demo_act_t_ph, train_task_idx)), axis=1),\n",
    "    n_act_dim, q_scope+'-'+str(train_task_idx), \n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation\n",
    "  ), \n",
    "  tf.concat([\n",
    "    demo_batch_idxes, \n",
    "    tf.expand_dims(extract_task(demo_act_t_ph, train_task_idx), 1)], axis=1)\n",
    ") for train_task_idx in range(n_train_tasks)], axis=0)\n",
    "\n",
    "\n",
    "demo_v_t_inputs = []\n",
    "for i in range(n_train_tasks):\n",
    "    obs = tf.tile(tf.expand_dims(extract_task(demo_obs_t_ph, train_task_idx),-1), [1,1,n_act_samples])\n",
    "    demo_v_t_inputs += [inp]\n",
    "    \n",
    "\n",
    "demo_v_t = tf.reduce_logsumexp(\n",
    "  tf.stack([build_mlp(\n",
    "    tf.concat((extract_task(demo_obs_t_ph, train_task_idx),  extract_task(sample_act_t_ph, train_task_idx)), axis=1),\n",
    "    n_act_dim, q_scope+'-'+str(train_task_idx), \n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation,\n",
    "    reuse=True\n",
    "  ) for train_task_idx in range(n_train_tasks)], axis=0),\n",
    "  axis=2)\n",
    "\n",
    "act_log_likelihoods = demo_q_t - demo_v_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_avg_log_likelihood = -tf.reduce_mean(act_log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_next_obs = build_mlp(\n",
    "  tf.concat((demo_obs_t_ph, demo_act_t_ph), axis=2),\n",
    "  n_obs_dim, invdyn_scope, \n",
    "  n_layers=invdyn_n_layers, size=invdyn_layer_size,\n",
    "  activation=invdyn_activation, output_activation=invdyn_output_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_next_obs_t_reshaped = tf.reshape(\n",
    "  demo_next_obs_t_ph, [n_train_tasks, demo_batch_size_ph, n_obs_feats])\n",
    "\n",
    "demo_pred_next_obs_t_reshaped = tf.reshape(\n",
    "    pred_next_obs, [n_train_tasks, demo_batch_size_ph, n_obs_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_err = pred_next_obs - demo_next_obs_t_ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_loss = tf.reduce_mean(trans_err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted constraint next state given inv dyns\n",
    "constraint_obs_tp1 = tf.reshape(build_mlp(\n",
    "  tf.concat((constraint_obs_t_ph, constraint_act_t_feats_ph), axis=2),\n",
    "  n_obs_dim, invdyn_scope, \n",
    "  n_layers=invdyn_n_layers, size=invdyn_layer_size,\n",
    "  activation=invdyn_activation, output_activation=invdyn_output_activation,\n",
    "  reuse=True), [n_train_tasks, constraint_batch_size_ph, n_obs_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_tp1 = tf.stack([build_mlp(\n",
    "    extract_task(constraint_obs_tp1, train_task_idx), \n",
    "    n_act_dim, q_scope+'-'+str(train_task_idx),\n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation, \n",
    "    reuse=True) for train_task_idx in range(n_train_tasks)], axis=0)\n",
    "v_tp1 = tf.reduce_logsumexp(q_tp1, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_t = constraint_rew_t_ph + gamma * v_tp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_batch_idxes = tf.reshape(\n",
    "  tf.range(0, constraint_batch_size_ph, 1), \n",
    "  [constraint_batch_size_ph, 1])\n",
    "\n",
    "# Sampled constraint state q-vals\n",
    "q_t = tf.stack([tf.gather_nd(\n",
    "  build_mlp(\n",
    "    extract_task(constraint_obs_t_ph, train_task_idx), \n",
    "    n_act_dim, q_scope+'-'+str(train_task_idx), \n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation, \n",
    "    reuse=True\n",
    "  ), \n",
    "  tf.concat([\n",
    "    constraint_batch_idxes, \n",
    "    tf.expand_dims(extract_task(constraint_act_t_ph, train_task_idx), 1)], axis=1)\n",
    ") for train_task_idx in range(n_train_tasks)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bellman errors\n",
    "td_err = q_t - target_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_td_err = tf.reduce_mean(td_err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = neg_avg_log_likelihood + sq_td_err_penalty * sq_td_err + trans_err_penalty * trans_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_update_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "trans_update_op = tf.train.AdamOptimizer(learning_rate).minimize(trans_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_constraints(_):\n",
    "  constraint_rollouts = [[] for _ in range(n_train_tasks)]\n",
    "  \n",
    "  for train_task_idx in range(n_train_tasks):\n",
    "    rollouts = [[] for _ in range(n_constraint_rollouts_per_env)]\n",
    "    envs = [make_lander_env(\n",
    "      fps=fps, goal=train_goals[train_task_idx]) for _ in range(\n",
    "      n_constraint_rollouts_per_env)]\n",
    "    obses = np.array([env.reset() for env in envs])\n",
    "    dones = [False for _ in envs]\n",
    "    prev_obses = obses\n",
    "    for step_idx in range(max_ep_len+1):\n",
    "      not_done_idxes = [i for i, done in enumerate(dones) if not done]\n",
    "      batch_size = len(not_done_idxes)\n",
    "      if batch_size == 0:\n",
    "        break\n",
    "      actions = np.random.choice(n_act_dim, batch_size)\n",
    "      for i, env_idx in enumerate(not_done_idxes):\n",
    "        env = envs[env_idx]\n",
    "        action = actions[i]\n",
    "        obs, r, done, info = env.step(action)\n",
    "        obses[env_idx] = obs\n",
    "        dones[env_idx] = done\n",
    "        rollouts[env_idx].append((\n",
    "          prev_obses[env_idx], action, r))\n",
    "      prev_obses = copy(obses)\n",
    "    constraint_rollouts[train_task_idx].extend([r for r in rollouts if r != []])\n",
    "\n",
    "  size = min(sum(len(r) for r in rollouts) for rollouts in constraint_rollouts)\n",
    "  \n",
    "  global train_constraint_example_idxes\n",
    "  global val_constraint_batch\n",
    "  global constraint_obs_t\n",
    "  global constraint_act_t\n",
    "  global constraint_rew_t\n",
    "  global constraint_act_t_feats\n",
    "    \n",
    "  constraint_obs_t = np.zeros((n_train_tasks, size, n_obs_feats))\n",
    "  constraint_act_t = np.zeros((n_train_tasks, size))\n",
    "  constraint_act_t_feats = np.zeros((n_train_tasks, size, n_act_feats))\n",
    "  constraint_rew_t = np.zeros((n_train_tasks, size))\n",
    "  \n",
    "  for train_task_idx in range(n_train_tasks):\n",
    "    unfeat_obses, actions, rews = list(zip(*sum(\n",
    "      constraint_rollouts[train_task_idx], [])))\n",
    "    obses = [featurize_obs(s) for s in unfeat_obses]\n",
    "    act_feats = [disc_to_cont(a) for a in actions]\n",
    "    idxes = random.sample(list(range(len(obses))), size)\n",
    "    constraint_obs_t[train_task_idx, :, :] = np.array(obses)[idxes, :]\n",
    "    constraint_act_t[train_task_idx, :] = np.array(actions)[idxes]\n",
    "    constraint_rew_t[train_task_idx, :] = np.array(rews)[idxes]\n",
    "    constraint_act_t_feats[train_task_idx, :, :] = np.array(act_feats)[idxes, :]\n",
    "\n",
    "  \n",
    "  constraint_example_idxes = list(range(size))\n",
    "  random.shuffle(constraint_example_idxes)\n",
    "  n_train_constraint_examples = int(0.9 * size)\n",
    "  \n",
    "  train_constraint_example_idxes = constraint_example_idxes[:n_train_constraint_examples]\n",
    "  val_constraint_example_idxes = constraint_example_idxes[n_train_constraint_examples:]\n",
    "  val_constraint_batch = (constraint_obs_t[:, val_constraint_example_idxes],\n",
    "                          constraint_act_t[:, val_constraint_example_idxes],\n",
    "                          constraint_act_t_feats[:, val_constraint_example_idxes],\n",
    "                          constraint_rew_t[:, val_constraint_example_idxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_constraint_batch(size):\n",
    "  global n_iters_since_prev_constraint_sample\n",
    "  if n_iters_since_prev_constraint_sample % constraint_sampling_freq == 0:\n",
    "    sample_constraints(size)\n",
    "    n_iters_since_prev_constraint_sample = 0\n",
    "  n_iters_since_prev_constraint_sample += 1\n",
    "\n",
    "  idxes = random.sample(train_constraint_example_idxes, size)\n",
    "  constraint_batch = (constraint_obs_t[:, idxes],\n",
    "    constraint_act_t[:, idxes],\n",
    "    constraint_act_t_feats[:, idxes],\n",
    "    constraint_rew_t[:, idxes])\n",
    "  return constraint_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_constraint_example_idxes = None\n",
    "val_constraint_batch = None\n",
    "constraint_obs_t = None\n",
    "constraint_act_t = None\n",
    "constraint_act_t_feats = None\n",
    "constraint_rew_t = None\n",
    "n_iters_since_prev_constraint_sample = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'constraint_samples.pkl'), 'wb') as f:\n",
    "  pickle.dump((\n",
    "    train_constraint_example_idxes, \n",
    "    val_constraint_batch,\n",
    "    constraint_obs_t,\n",
    "    constraint_act_t,\n",
    "    constraint_act_t_feats,\n",
    "    constraint_rew_t,\n",
    "    n_iters_since_prev_constraint_sample), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'constraint_samples.pkl'), 'rb') as f:\n",
    "  (train_constraint_example_idxes, \n",
    "    val_constraint_batch,\n",
    "    constraint_obs_t,\n",
    "    constraint_act_t,\n",
    "    constraint_act_t_feats,\n",
    "    constraint_rew_t,\n",
    "    n_iters_since_prev_constraint_sample) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iters = iterations * demo_obs.shape[1] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_loss(demo_batch, constraint_batch, step=False, trans_only=False, t=None):\n",
    "  demo_batch_obs_t, demo_batch_act_t, demo_batch_act_t_feats, demo_batch_next_obs_t = demo_batch\n",
    "  constraint_batch_obs_t, constraint_batch_act_t, constraint_batch_act_t_feats, constraint_batch_rew_t = constraint_batch\n",
    "\n",
    "  feed_dict = {\n",
    "    demo_obs_t_ph: demo_batch_obs_t,\n",
    "    demo_act_t_ph: demo_batch_act_t,\n",
    "    demo_act_t_feats_ph: demo_batch_act_t_feats,\n",
    "    demo_next_obs_t_ph: demo_batch_next_obs_t,\n",
    "    demo_batch_size_ph: demo_batch_obs_t.shape[1],\n",
    "    constraint_obs_t_ph: constraint_batch_obs_t,\n",
    "    constraint_act_t_ph: constraint_batch_act_t,\n",
    "    constraint_act_t_feats_ph: constraint_batch_act_t_feats,\n",
    "    constraint_rew_t_ph: constraint_batch_rew_t,\n",
    "    constraint_batch_size_ph: constraint_batch_obs_t.shape[1],\n",
    "  }\n",
    "  \n",
    "  if trans_only:\n",
    "    [loss_eval] = sess.run([trans_loss], feed_dict=feed_dict)\n",
    "    update_op = trans_update_op\n",
    "    d = {\n",
    "    'loss': loss_eval,\n",
    "      }\n",
    "  else:\n",
    "    [loss_eval, neg_avg_log_likelihood_eval, sq_td_err_eval, trans_loss_eval] = sess.run(\n",
    "        [loss, neg_avg_log_likelihood, sq_td_err, trans_loss], feed_dict=feed_dict)\n",
    "    update_op = full_update_op\n",
    "    d = {\n",
    "        'loss': loss_eval,\n",
    "        'nll': neg_avg_log_likelihood_eval,\n",
    "        'ste': sq_td_err_eval,\n",
    "        'tl': trans_loss_eval\n",
    "      }\n",
    "  \n",
    "  if step:\n",
    "    sess.run(update_op, feed_dict=feed_dict)\n",
    "#   else:\n",
    "#     d.update(compute_int_dyn_nll())\n",
    "    \n",
    "#   print(sess.run([q_t], feed_dict=feed_dict)[0].shape)\n",
    "#   print(sess.run([target_t], feed_dict=feed_dict)[0].shape)\n",
    "\n",
    "\n",
    "  return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Dynamics with Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_logs = {\n",
    "  'loss_evals': [],\n",
    "  'tl_evals': [],\n",
    "  'nll_evals': [],\n",
    "  'ste_evals': [],\n",
    "  'val_loss_evals': [],\n",
    "  'val_tl_evals': [],\n",
    "  'val_nll_evals': [],\n",
    "  'val_ste_evals': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_log = None\n",
    "while len(full_train_logs['loss_evals']) < n_iters:\n",
    "  demo_batch = sample_batch(batch_size)\n",
    "  constraint_batch = sample_constraint_batch(constraint_batch_size)\n",
    "  t = len(full_train_logs['loss_evals'])\n",
    "  train_log = compute_batch_loss(demo_batch, constraint_batch, step=True, t=t)\n",
    "  if val_log is None or len(full_train_logs['loss_evals']) % val_update_freq == 0:\n",
    "    val_log = compute_batch_loss(val_demo_batch, val_constraint_batch, step=False, t=t)\n",
    "  \n",
    "  if len(full_train_logs['loss_evals']) % 1000 == 0:\n",
    "      print('%d %d %f %f %f %f' % (\n",
    "        t, n_iters, train_log['loss'], train_log['tl'], val_log['loss'], val_log['tl'])\n",
    "      )\n",
    "  for k, v in train_log.items():\n",
    "    full_train_logs['%s_evals' % k].append(v)\n",
    "  for k, v in val_log.items():\n",
    "    full_train_logs['%s%s_evals' % ('val_' if k in ['loss', 'nll', 'ste', 'tl'] else '', k)].append(v)\n",
    "  if len(full_train_logs['loss_evals']) % 10000 == 0:\n",
    "    for k in ['val_nll_evals', 'val_ste_evals']:\n",
    "      plt.xlabel('Iterations')\n",
    "      plt.ylabel(k.split('_')[1])\n",
    "      plt.plot(full_train_logs[k])\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in ['val_nll_evals', 'val_ste_evals']:\n",
    "  plt.xlabel('Iterations')\n",
    "  plt.ylabel(k.split('_')[1])\n",
    "  plt.plot(full_train_logs[k])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invdyn_r_path = os.path.join(data_dir, 'invdyn_r.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_tf_vars(sess, invdyn_scope, invdyn_r_path)\n",
    "load_tf_vars(sess, invdyn_scope, invdyn_r_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'qt_results.pkl'), 'wb') as f:\n",
    "  pickle.dump(full_train_logs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Dynamics Without Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_constraint_example_idxes = None\n",
    "val_constraint_batch = None\n",
    "constraint_obs_t = None\n",
    "constraint_act_t = None\n",
    "constraint_act_t_feats = None\n",
    "n_iters_since_prev_constraint_sample = 0\n",
    "\n",
    "tf.global_variables_initializer().run(session=sess)\n",
    "\n",
    "n_iters = iterations * demo_obs.shape[1] // batch_size\n",
    "\n",
    "trans_train_logs = {\n",
    "  'loss_evals': [],\n",
    "  'nll_evals': [],\n",
    "  'ste_evals': [],\n",
    "  'val_loss_evals': [],\n",
    "  'val_nll_evals': [],\n",
    "  'val_ste_evals': [],\n",
    "  'int_dyn_err_evals': []\n",
    "}\n",
    "val_log = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while len(trans_train_logs['loss_evals']) < n_iters:\n",
    "  demo_batch = sample_batch(batch_size)\n",
    "  constraint_batch = sample_constraint_batch(constraint_batch_size)\n",
    "  \n",
    "  t = len(trans_train_logs['loss_evals'])\n",
    "  train_log = compute_batch_loss(demo_batch, constraint_batch, trans_only=True, step=True, t=t)\n",
    "  if val_log is None or len(trans_train_logs['loss_evals']) % val_update_freq == 0:\n",
    "    val_log = compute_batch_loss(val_demo_batch, val_constraint_batch, trans_only=True, step=False, t=t)\n",
    "  \n",
    "  if len(trans_train_logs['loss_evals']) % 1000 == 0:\n",
    "      print('%d %d %f %f' % (\n",
    "        t, n_iters, train_log['loss'], val_log['loss'],)\n",
    "      )\n",
    "\n",
    "  trans_train_logs['loss_evals'].append(train_log['loss'])\n",
    "  trans_train_logs['val_loss_evals'].append(val_log['loss'])\n",
    "  if len(trans_train_logs['loss_evals']) % 10000 == 0:\n",
    "    for k in ['loss_evals', 'val_loss_evals']:\n",
    "      plt.xlabel('Iterations')\n",
    "      plt.ylabel(k.split('_')[1])\n",
    "      plt.plot(trans_train_logs[k])\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invdyn_nr_path = os.path.join(data_dir, 'invdyn_nr.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tf_vars(sess, invdyn_scope, invdyn_nr_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Q-vals for policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_task_idx = 3\n",
    "train_env = train_envs[train_task_idx]\n",
    "obs_t_ph = tf.placeholder(tf.float32, [None, n_obs_feats], name=\"ot\")\n",
    "\n",
    "training_qs = build_mlp(\n",
    "    obs_t_ph,\n",
    "    n_act_dim, q_scope+'-'+str(train_task_idx), \n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation,\n",
    "    reuse=True)\n",
    "\n",
    "policy_action = tf.argmax(training_qs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def run_q_pol_ep(policy_action, obs_ph, env, max_ep_len=max_ep_len, render=False, task_idx=None):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  totalr = 0.\n",
    "  prev_obs = obs\n",
    "  rollout = []\n",
    "  for step_idx in range(max_ep_len+1):\n",
    "    if done:\n",
    "      break\n",
    "    action = sess.run(policy_action, feed_dict={obs_ph:np.array([obs])})[0]\n",
    "    obs, r, done, info = env.step(action)\n",
    "    rollout.append((prev_obs, action, r, obs, float(done), task_idx))\n",
    "    prev_obs = obs\n",
    "    if render:\n",
    "      env.render()\n",
    "    totalr += r\n",
    "  return rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "run_q_pol_ep(policy_action, obs_t_ph, train_env, render=True, task_idx=train_task_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_envs[train_task_idx].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Q-vals for arbitrary goals using Bellman Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_t_ph = tf.placeholder(tf.float32, [None, n_obs_feats])\n",
    "act_t_ph = tf.placeholder(tf.int32, [None])\n",
    "act_t_feats_ph = tf.placeholder(tf.float32, [None, n_act_feats])\n",
    "next_obs_t_ph = tf.placeholder(tf.float32, [None, n_obs_feats])\n",
    "batch_size_ph = tf.placeholder(tf.int32)\n",
    "\n",
    "\n",
    "con_obs_t_ph = tf.placeholder(tf.float32, [None, n_obs_feats])\n",
    "con_act_t_ph = tf.placeholder(tf.int32, [None])\n",
    "con_act_t_feats_ph = tf.placeholder(tf.float32, [None, n_act_feats])\n",
    "con_rew_t_ph = tf.placeholder(tf.float32, [None])\n",
    "con_batch_size_ph = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=1):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    axis = 0 if len(x.shape) == 1 else axis\n",
    "    e_x = np.exp(x - np.max(x, axis=axis,keepdims=True))\n",
    "    return (e_x / e_x.sum(axis=axis, keepdims = True))\n",
    "\n",
    "def sample_q_learn_constraints(goal, n_samples=n_constraint_rollouts_per_env, q_fn = None):\n",
    "  constraint_rollouts = []\n",
    "  rollouts = [[] for _ in range(n_samples)]\n",
    "  envs = [make_lander_env(goal=goal) for _ in range(n_samples)]\n",
    "  obses = np.array([env.reset() for env in envs])\n",
    "  dones = [False for _ in envs]\n",
    "  prev_obses = obses\n",
    "  for step_idx in range(max_ep_len+1):\n",
    "    not_done_idxes = [i for i, done in enumerate(dones) if not done]\n",
    "    batch_size = len(not_done_idxes)\n",
    "    if batch_size == 0:\n",
    "      break\n",
    "    if q_fn is None:\n",
    "        actions = np.random.choice(n_act_dim, batch_size)\n",
    "    else:\n",
    "        action_probs = sess.run([q_fn], feed_dict={obs_t_ph: np.array(prev_obses)})[0]\n",
    "        actions = np.array([np.random.choice(n_act_dim, p=softmax(aps)) for aps in action_probs])\n",
    "    for i, env_idx in enumerate(not_done_idxes):\n",
    "      env = envs[env_idx]\n",
    "      action = actions[i]\n",
    "      obs, r, done, info = env.step(action)\n",
    "      obses[env_idx] = obs\n",
    "      dones[env_idx] = done\n",
    "      rollouts[env_idx].append((prev_obses[env_idx], action, r))\n",
    "      prev_obses = copy(obses)\n",
    "    constraint_rollouts.extend([r for r in rollouts if r != []])\n",
    "\n",
    "  size = sum(len(r) for r in rollouts)\n",
    "    \n",
    "  unfeat_obses, actions, rews = list(zip(*sum(constraint_rollouts, [])))\n",
    "  obses = [featurize_obs(s) for s in unfeat_obses]\n",
    "  act_feats = [disc_to_cont(a) for a in actions]\n",
    "  idxes = random.sample(list(range(len(obses))), size)\n",
    "  constraint_obs_t = np.array(obses)[idxes, :]\n",
    "  constraint_act_t = np.array(actions)[idxes]\n",
    "  constraint_rew_t = np.array(rews)[idxes]\n",
    "  constraint_act_t_feats = np.array(act_feats)[idxes, :]\n",
    "\n",
    "  \n",
    "  constraint_example_idxes = list(range(size))\n",
    "  random.shuffle(constraint_example_idxes)\n",
    "  n_train_constraint_examples = int(0.9 * size)\n",
    "  \n",
    "  train_constraint_example_idxes = constraint_example_idxes[:n_train_constraint_examples]\n",
    "  train_constraint_batch = [constraint_obs_t[train_constraint_example_idxes],\n",
    "                            constraint_act_t[train_constraint_example_idxes],\n",
    "                            constraint_act_t_feats[train_constraint_example_idxes],\n",
    "                            constraint_rew_t[train_constraint_example_idxes]]\n",
    "    \n",
    "  val_constraint_example_idxes = constraint_example_idxes[n_train_constraint_examples:]\n",
    "  val_constraint_batch = (constraint_obs_t[val_constraint_example_idxes],\n",
    "                          constraint_act_t[val_constraint_example_idxes],\n",
    "                          constraint_act_t_feats[val_constraint_example_idxes],\n",
    "                          constraint_rew_t[val_constraint_example_idxes])\n",
    "\n",
    "  return train_constraint_batch, val_constraint_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_q_learn_constraint_batch(size):\n",
    "  global train_constraints\n",
    "  train_constraint_example_idxes = list(range(len(train_constraints[0])))\n",
    "  idxes = random.sample(train_constraint_example_idxes, size)\n",
    "  constraint_batch = tuple(map(lambda x: x[idxes], train_constraints))\n",
    "  return constraint_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = 9\n",
    "qlearn_env = make_lander_env(goal=train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_constraints[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_obs_tp1 = build_mlp(\n",
    "  tf.concat((con_obs_t_ph, con_act_t_feats_ph), axis=1),\n",
    "  n_obs_dim, invdyn_scope, \n",
    "  n_layers=invdyn_n_layers, size=invdyn_layer_size,\n",
    "  activation=invdyn_activation, output_activation=invdyn_output_activation,\n",
    "  reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampled constraint state q-vals\n",
    "train_q_t = build_mlp(\n",
    "    con_obs_t_ph,\n",
    "    n_act_dim, q_scope+'-'+str(train_id), \n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_q_t = build_mlp(\n",
    "    obs_t_ph,\n",
    "    n_act_dim, q_scope+'-'+str(train_id), \n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation,\n",
    "    reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q_tp1 = build_mlp(\n",
    "    con_obs_tp1, \n",
    "    n_act_dim, q_scope+'-'+str(train_id),\n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation,\n",
    "    reuse=True)\n",
    "\n",
    "train_v_tp1 = tf.reduce_logsumexp(train_q_tp1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_t = con_rew_t_ph + gamma * train_v_tp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bellman errors\n",
    "train_td_err = tf.transpose(tf.transpose(train_q_t) - train_target_t)\n",
    "train_sq_td_err = tf.reduce_mean(train_td_err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, q_scope+'-'+str(train_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_update_op = tf.train.AdamOptimizer(learning_rate).minimize(train_sq_td_err, var_list=q_train_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_qbatch_loss(constraint_batch, update_op, step=True):\n",
    "  constraint_batch_obs_t, constraint_batch_act_t, constraint_batch_act_t_feats, constraint_batch_rew_t = constraint_batch\n",
    "\n",
    "  feed_dict = {\n",
    "    con_obs_t_ph: constraint_batch_obs_t,\n",
    "    con_act_t_ph: constraint_batch_act_t,\n",
    "    con_act_t_feats_ph: constraint_batch_act_t_feats,\n",
    "    con_rew_t_ph: constraint_batch_rew_t,\n",
    "    con_batch_size_ph: constraint_batch_obs_t.shape[1],\n",
    "  }\n",
    "\n",
    "  sq_td_err_eval = sess.run([train_sq_td_err], feed_dict=feed_dict)[0]\n",
    "  \n",
    "  if step:\n",
    "      sess.run(update_op, feed_dict=feed_dict)\n",
    "    \n",
    "  return sq_td_err_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_constraints, val_constraints = sample_q_learn_constraints(train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run(session=sess)\n",
    "load_tf_vars(sess, invdyn_scope, invdyn_r_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_train_logs = {\n",
    "  'err': [],\n",
    "  'val_err':[]\n",
    "}\n",
    "max_iters = 1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_err = None\n",
    "while len(soft_train_logs['err']) < max_iters:\n",
    "  constraint_batch = sample_q_learn_constraint_batch(constraint_batch_size)\n",
    "  t = len(soft_train_logs['err'])\n",
    "  err = compute_qbatch_loss(constraint_batch, train_update_op)\n",
    "  if val_err is None or len(soft_train_logs['val_err']) % val_update_freq == 0:\n",
    "    val_err = compute_qbatch_loss(val_constraints, train_update_op, step=False)\n",
    "  if len(soft_train_logs['err']) % 1000 == 0:\n",
    "      print('%d %d %f %f' % (t, n_iters, err, val_err))\n",
    "  soft_train_logs['err'].append(err)\n",
    "  soft_train_logs['val_err'].append(val_err)\n",
    "  if len(soft_train_logs['err']) % 10000 == 0:\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel(\"Validation Residual Error\")\n",
    "    plt.plot(soft_train_logs['val_err'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_train_logs = {\n",
    "  'err': [],\n",
    "  'val_errs':[[]]\n",
    "}\n",
    "max_iters = 1e6\n",
    "\n",
    "val_errs = []\n",
    "dagger_iter_rate = 2e4\n",
    "dagger_constraint_sims = 10\n",
    "val_constraint_list = [val_constraints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(soft_train_logs['err']) < max_iters:\n",
    "  if len(soft_train_logs['err']) % dagger_iter_rate == 0 and len(soft_train_logs['err']) != 0:\n",
    "    print(\"Generating new rollouts\")\n",
    "    new_train_cons, new_val_cons = sample_q_learn_constraints(train_id, dagger_constraint_sims, pol_q_t)\n",
    "    n_new_cons = new_train_cons[0].shape[0]\n",
    "    for i in range(len(train_constraints)):\n",
    "        print(train_constraints[i].shape, new_train_cons[i].shape)\n",
    "        if len(train_constraints[i].shape) == 2:\n",
    "            train_constraints[i] = np.vstack((train_constraints[i], new_train_cons[i]))[n_new_cons:]\n",
    "        else:\n",
    "            train_constraints[i] = np.append(train_constraints[i], new_train_cons[i])[n_new_cons:]\n",
    "    val_constraint_list += [new_val_cons]\n",
    "    soft_train_logs['val_errs'] += [[]]\n",
    "  constraint_batch = sample_q_learn_constraint_batch(constraint_batch_size)\n",
    "  t = len(soft_train_logs['err'])\n",
    "  err = compute_qbatch_loss(constraint_batch, train_update_op)\n",
    "  if len(val_errs) == 0 or len(soft_train_logs['val_errs'][0]) % val_update_freq == 0:\n",
    "    for i,val_cons in enumerate(val_constraint_list):\n",
    "        val_err = compute_qbatch_loss(val_cons, train_update_op, step=False)\n",
    "        soft_train_logs['val_errs'][i].append(val_err)\n",
    "\n",
    "  if len(soft_train_logs['err']) % 1000 == 0:\n",
    "      print('%d %d %f %f' % (t, n_iters, err, val_err))\n",
    "  soft_train_logs['err'].append(err)\n",
    "  if len(soft_train_logs['err']) % 10000 == 0:\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel(\"Validation Residual Error\")\n",
    "    for val_err in soft_train_logs['val_errs']:\n",
    "        plt.plot(val_err)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_policy(obs):\n",
    "    policy_action = tf.argmax(pol_q_t, axis=1)\n",
    "    return sess.run([policy_action], feed_dict = {obs_t_ph : np.array([obs])})[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ep(q_policy, train_env, max_ep_len=max_ep_len, render=True, task_idx=None)\n",
    "qlearn_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPC-R attempt [failed due to difficulties with contactlisteners]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_t_ph = tf.placeholder(tf.float32, [None, n_obs_feats], name=\"ot\")\n",
    "act_t_feats_ph = tf.placeholder(tf.float32, [None, n_act_feats], name=\"atf\")\n",
    "\n",
    "obs_tp1 = build_mlp(\n",
    "  tf.concat((obs_t_ph, act_t_feats_ph), axis=1),\n",
    "  n_obs_dim, invdyn_scope, \n",
    "  n_layers=invdyn_n_layers, size=invdyn_layer_size,\n",
    "  activation=invdyn_activation, output_activation=invdyn_output_activation,\n",
    "  reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = MPCController(train_env, train_env.env._reward, obs_t_ph, act_t_feats_ph, obs_tp1, sess, 100, 50, gamma, n_act_dim, featurize_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_controller_ep(policy, env, max_ep_len=max_ep_len, render=False, task_idx=None):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  totalr = 0.\n",
    "  prev_obs = obs\n",
    "  rollout = []\n",
    "  for step_idx in range(max_ep_len+1):\n",
    "    if done:\n",
    "      break\n",
    "    action = policy(obs, step_idx)\n",
    "    obs, r, done, info = env.step(action)\n",
    "    rollout.append((prev_obs, action, r, obs, float(done), task_idx))\n",
    "    prev_obs = obs\n",
    "    if render:\n",
    "      env.render()\n",
    "    totalr += r\n",
    "  return rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "run_controller_ep(controller.get_action, train_env, max_ep_len=max_ep_len, render=False, task_idx=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "def do_cprofile(func):\n",
    "    def profiled_func(*args, **kwargs):\n",
    "        profile = cProfile.Profile()\n",
    "        try:\n",
    "            profile.enable()\n",
    "            result = func(*args, **kwargs)\n",
    "            profile.disable()\n",
    "            return result\n",
    "        finally:\n",
    "            profile.print_stats()\n",
    "    return profiled_func\n",
    "\n",
    "\n",
    "profiled_run_ep = do_cprofile(run_controller_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiled_run_ep(controller.get_action, train_env, max_ep_len=max_ep_len, render=True, task_idx=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from line_profiler import LineProfiler\n",
    "\n",
    "def do_profile(follow=[]):\n",
    "    def inner(func):\n",
    "        def profiled_func(*args, **kwargs):\n",
    "            try:\n",
    "                profiler = LineProfiler()\n",
    "                profiler.add_function(func)\n",
    "                for f in follow:\n",
    "                    profiler.add_function(f)\n",
    "                profiler.enable_by_count()\n",
    "                return func(*args, **kwargs)\n",
    "            finally:\n",
    "                profiler.print_stats()\n",
    "        return profiled_func\n",
    "    return inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@do_profile(follow=[train_env.env._reward,controller.get_action])\n",
    "def lp_run_controller_ep(policy, env, max_ep_len=max_ep_len, render=False, task_idx=None):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  totalr = 0.\n",
    "  prev_obs = obs\n",
    "  rollout = []\n",
    "  for step_idx in range(max_ep_len+1):\n",
    "    if done:\n",
    "      break\n",
    "    action = policy(obs, step_idx)\n",
    "    obs, r, done, info = env.step(action)\n",
    "    rollout.append((prev_obs, action, r, obs, float(done), task_idx))\n",
    "    prev_obs = obs\n",
    "    if render:\n",
    "      env.render()\n",
    "    totalr += r\n",
    "  return rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_run_controller_ep(controller.get_action, train_env, max_ep_len=max_ep_len, render=False, task_idx=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
