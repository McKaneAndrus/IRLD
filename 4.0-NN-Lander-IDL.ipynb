{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pickle\n",
    "import os\n",
    "import types\n",
    "import random\n",
    "import uuid\n",
    "import math\n",
    "from copy import deepcopy as copy\n",
    "import logging\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.envs.classic_control import rendering\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.misc import logsumexp\n",
    "from baselines import deepq\n",
    "import baselines.common.tf_util as U\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rllab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f57103da7124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnn_dynamics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPCController\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Masters Research/IRLD/IRLD/nn_dynamics/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmpc_controller\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPCController\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'MPCController'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Masters Research/IRLD/IRLD/nn_dynamics/mpc_controller.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrllab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_manipulation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_observation_to_usablestate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreward_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRewardFunctions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rllab'"
     ]
    }
   ],
   "source": [
    "from nn_dynamics import MPCController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('savefig', dpi=300)\n",
    "mpl.rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = logging.getLogger('root')\n",
    "# print(logger.hasHandlers())\n",
    "# assert len(logger.handlers) == 1\n",
    "# handler = logger.handlers[0]\n",
    "# handler.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join('data', '4.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create envs, pilot policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throttle_mag = 0.75\n",
    "def disc_to_cont(action):\n",
    "  if type(action) == np.ndarray:\n",
    "    return action\n",
    "  # main engine\n",
    "  if action < 3:\n",
    "    m = -throttle_mag\n",
    "  elif action < 6:\n",
    "    m = throttle_mag\n",
    "  else:\n",
    "    raise ValueError\n",
    "  # steering\n",
    "  if action % 3 == 0:\n",
    "    s = -throttle_mag\n",
    "  elif action % 3 == 1:\n",
    "    s = 0\n",
    "  else:\n",
    "    s = throttle_mag\n",
    "  return np.array([m, s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_act_dim = 6\n",
    "n_obs_dim = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ep_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_goals = np.arange(1, 10, 1).astype(int)\n",
    "n_train_tasks = train_goals.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lander_env(fps=fps, goal=None):\n",
    "  env = gym.make('LunarLanderContinuous-v2')\n",
    "  env.unwrapped.goal = goal\n",
    "  env.action_space = spaces.Discrete(n_act_dim)\n",
    "  env.unwrapped._step_orig = env.unwrapped.step\n",
    "  def step(self, action):\n",
    "    obs, r, done, info = self._step_orig(disc_to_cont(action))\n",
    "    return obs, r, done, info\n",
    "  env.unwrapped.step = types.MethodType(step, env.unwrapped)\n",
    "  env.unwrapped.fps = fps\n",
    "  return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_newton_envs = [make_lander_env(fps=fast_fps, goal=goal) for goal in train_goals]\n",
    "train_envs = [make_lander_env(fps=fps, goal=goal) for goal in train_goals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ep(policy, env, max_ep_len=max_ep_len, render=False, task_idx=None):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  totalr = 0.\n",
    "  prev_obs = obs\n",
    "  rollout = []\n",
    "  for step_idx in range(max_ep_len+1):\n",
    "    if done:\n",
    "      break\n",
    "    action = policy(obs)\n",
    "    obs, r, done, info = env.step(action)\n",
    "    rollout.append((prev_obs, action, r, obs, float(done), task_idx))\n",
    "    prev_obs = obs\n",
    "    if render:\n",
    "      env.render()\n",
    "    totalr += r\n",
    "  return rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train agent with soft dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = make_lander_env(fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_episodes = 800\n",
    "load_pretrained_pilot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_q_func = lambda: deepq.models.mlp([64, 64])\n",
    "dqn_learn_kwargs = {\n",
    "  'lr': 1e-3,\n",
    "  'target_network_update_freq': 3000,\n",
    "  'print_freq': 100,\n",
    "  'max_timesteps': max_ep_len * (1 if load_pretrained_pilot else n_training_episodes)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'dqn_pilot_scope.pkl'), 'rb') as f:\n",
    "  dqn_pilot_scope = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dqn_pilot_scope = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env.action_space #.contains(np.int64(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dqn_pilot_policy, _ = deepq.learn(\n",
    "  train_env,\n",
    "  q_func=make_q_func(),\n",
    "  scope=dqn_pilot_scope,\n",
    "  **dqn_learn_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(data_dir, 'dqn_pilot_scope.pkl'), 'wb') as f:\n",
    "#   pickle.dump(dqn_pilot_scope, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_pilot_path = os.path.join(data_dir, 'dqn_pilot.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tf_vars(sess, scope, path):\n",
    "  saver = tf.train.Saver([v for v in tf.global_variables() if v.name.startswith(scope + '/')])\n",
    "  saver.save(sess, save_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_vars(sess, scope, path):\n",
    "  saver = tf.train.Saver([v for v in tf.global_variables() if v.name.startswith(scope + '/')])\n",
    "  saver.restore(sess, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_tf_vars(U.get_session(), dqn_pilot_scope, dqn_pilot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_tf_vars(U.get_session(), dqn_pilot_scope, dqn_pilot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEWPORT_W = 600\n",
    "VIEWPORT_H = 400\n",
    "SCALE = 30.0\n",
    "W = VIEWPORT_W/SCALE\n",
    "H = VIEWPORT_H/SCALE\n",
    "CHUNKS = 11\n",
    "chunk_x = [W/(CHUNKS-1)*i for i in range(CHUNKS)]\n",
    "helipad_xs = [(chunk_x[goal-1]+chunk_x[goal+1])/2 for goal in train_goals]\n",
    "train_goal_obses = [(helipad_x - VIEWPORT_W/SCALE/2) / (VIEWPORT_W/SCALE/2) for helipad_x in helipad_xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 1\n",
    "def make_pilot_policy(train_task_idx):\n",
    "  goal_obs = train_goal_obses[train_task_idx]\n",
    "  def pilot_policy(obs):\n",
    "    my_obs = copy(obs)\n",
    "    my_obs[8] = goal_obs\n",
    "    with tf.variable_scope(dqn_pilot_scope, reuse=None):\n",
    "      return raw_dqn_pilot_policy._act(my_obs[None, :], temperature=temperature)[0]\n",
    "  return pilot_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_policies = [make_pilot_policy(train_task_idx) for train_task_idx in range(n_train_tasks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pilot_policy(train_task_idx):\n",
    "  return pilot_policies[train_task_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sanity-check envs, agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_task_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run_ep(pilot_policies[train_task_idx], train_envs[train_task_idx], render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_envs[train_task_idx].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run_ep(pilot_policies[train_task_idx], train_newton_envs[train_task_idx], render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_newton_envs[train_task_idx].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit internal dynamics model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_train_rollouts_per_env = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# demo_rollouts = [[run_ep(pilot_policies[train_task_idx], newton_env, render=False, task_idx=train_task_idx)          \n",
    "#                   for _ in range(n_train_rollouts_per_env)]\n",
    "#                  for train_task_idx, newton_env in enumerate(train_newton_envs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(os.path.join(data_dir, 'pilot_policy_demo_rollouts.pkl'), 'wb') as f:\n",
    "#   pickle.dump(demo_rollouts, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_rollouts_path = os.path.join('data', '5.1-lander-newton', 'sid_pilot_policy_demo_rollouts.pkl')\n",
    "demo_rollouts_path = os.path.join(data_dir, 'pilot_policy_demo_rollouts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(demo_rollouts_path, 'rb') as f:\n",
    "  demo_rollouts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(\n",
    "    input_placeholder,\n",
    "    output_size,\n",
    "    scope,\n",
    "    n_layers=1,\n",
    "    size=256,\n",
    "    activation=tf.nn.relu,\n",
    "    output_activation=None,\n",
    "    reuse=False\n",
    "  ):\n",
    "  out = input_placeholder\n",
    "  with tf.variable_scope(scope, reuse=reuse):\n",
    "    for _ in range(n_layers):\n",
    "      out = tf.layers.dense(out, size, activation=activation)\n",
    "    out = tf.layers.dense(out, output_size, activation=output_activation)\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs_feats = n_obs_dim\n",
    "featurize_obs = lambda s: s\n",
    "n_act_feats = 2\n",
    "featurize_act = lambda a: [disc_to_cont(act) for act in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vectorize_rollouts(rollouts):\n",
    "  obs = [[] for _ in range(n_train_tasks)]\n",
    "  actions = [[] for _ in range(n_train_tasks)]\n",
    "  next_obs = [[] for _ in range(n_train_tasks)]\n",
    "  for task_idx, task_rollouts in enumerate(rollouts):\n",
    "    for task_rollout in task_rollouts:\n",
    "      more_obs, more_actions, _, more_next_obs = list(zip(*task_rollout))[:4]\n",
    "      obs[task_idx].extend([featurize_obs(s) for s in more_obs])\n",
    "      actions[task_idx].extend(more_actions)\n",
    "      next_obs[task_idx].extend([featurize_obs(s) for s in more_next_obs])\n",
    "  l = min(len(x) for x in obs)\n",
    "  idxes = [random.sample(list(range(len(x))), l) for x in obs]\n",
    "  f = lambda x: np.array(x[1])[idxes[x[0]]]\n",
    "  obs = np.array(list(map(f, enumerate(obs))))\n",
    "  actions = np.array(list(map(f, enumerate(actions))))\n",
    "  action_feats = np.array([featurize_act(a) for a in actions])\n",
    "  next_obs = np.array(list(map(f, enumerate(next_obs))))\n",
    "\n",
    "  return obs, actions, action_feats, next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_obs = None\n",
    "demo_actions = None\n",
    "demo_act_feats = None\n",
    "demo_next_obs = None\n",
    "demo_task_idxes = None\n",
    "train_demo_example_idxes = None\n",
    "val_demo_batch = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_demo_rollouts(demo_rollouts):\n",
    "  global demo_obs\n",
    "  global demo_actions\n",
    "  global demo_act_feats\n",
    "  global demo_next_obs\n",
    "  global demo_task_idxes\n",
    "  global train_demo_example_idxes\n",
    "  global val_demo_batch\n",
    "\n",
    "  \n",
    "  demo_obs, demo_actions, demo_act_feats, demo_next_obs = vectorize_rollouts(demo_rollouts)\n",
    "  demo_example_idxes = list(range(demo_obs.shape[1]))\n",
    "  \n",
    "  random.shuffle(demo_example_idxes)\n",
    "  n_train_demo_examples = int(0.9 * len(demo_example_idxes))\n",
    "  train_demo_example_idxes = demo_example_idxes[:n_train_demo_examples]\n",
    "  val_demo_example_idxes = demo_example_idxes[n_train_demo_examples:]\n",
    "  val_demo_batch = (demo_obs[:, val_demo_example_idxes], demo_actions[:, val_demo_example_idxes],\n",
    "        demo_act_feats[:, val_demo_example_idxes], demo_next_obs[:, val_demo_example_idxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_demo_rollouts(demo_rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(size):\n",
    "  idxes = random.sample(train_demo_example_idxes, size)\n",
    "  demo_batch = demo_obs[:, idxes], demo_actions[:, idxes], demo_act_feats[:, idxes], demo_next_obs[:, idxes]\n",
    "  return demo_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "iterations = 100000\n",
    "learning_rate = 1e-3\n",
    "batch_size = 512 // n_train_tasks\n",
    "sq_td_err_penalty = 1e-3\n",
    "trans_err_penalty = 1e0\n",
    "\n",
    "\n",
    "q_n_layers = 1\n",
    "q_layer_size = 32\n",
    "q_activation = tf.nn.relu\n",
    "q_output_activation = None\n",
    "\n",
    "invdyn_n_layers = 1\n",
    "invdyn_layer_size = 32\n",
    "invdyn_activation = tf.nn.relu\n",
    "invdyn_output_activation = None\n",
    "\n",
    "\n",
    "constraint_sampling_freq = 100000\n",
    "constraint_batch_size = batch_size\n",
    "n_constraint_rollouts_per_env = 100\n",
    "\n",
    "val_update_freq = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im_scope = str(uuid.uuid4())\n",
    "q_scope = str(uuid.uuid4())\n",
    "invdyn_scope = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo_obs_t_ph = tf.placeholder(tf.float32, [n_train_tasks, None, n_obs_feats], name=\"dot\")\n",
    "demo_act_t_ph = tf.placeholder(tf.int32, [n_train_tasks, None], name=\"dat\")\n",
    "demo_act_t_feats_ph = tf.placeholder(tf.float32, [n_train_tasks, None, n_act_feats], name=\"datf\")\n",
    "demo_next_obs_t_ph = tf.placeholder(tf.float32, [n_train_tasks, None, n_obs_feats], name=\"dnot\")\n",
    "demo_batch_size_ph = tf.placeholder(tf.int32, name=\"dbs\")\n",
    "\n",
    "\n",
    "constraint_obs_t_ph = tf.placeholder(tf.float32, [n_train_tasks, None, n_obs_feats], name=\"cot\")\n",
    "constraint_act_t_ph = tf.placeholder(tf.int32, [n_train_tasks, None], name=\"cat\")\n",
    "constraint_act_t_feats_ph = tf.placeholder(tf.float32, [n_train_tasks, None, n_act_feats], name=\"catf\")\n",
    "constraint_rew_t_ph = tf.placeholder(tf.float32, [n_train_tasks, None], name=\"crt\")\n",
    "constraint_batch_size_ph = tf.placeholder(tf.int32, name=\"cbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo_batch_idxes = tf.reshape(\n",
    "  tf.range(0, demo_batch_size_ph, 1), \n",
    "  [demo_batch_size_ph, 1])\n",
    "\n",
    "extract_task = lambda x, i: tf.squeeze(tf.gather(x, tf.convert_to_tensor(\n",
    "  [i], dtype=tf.int32)), axis=[0]) \n",
    "\n",
    "demo_q_t = tf.stack([tf.gather_nd(\n",
    "  build_mlp(\n",
    "    extract_task(demo_obs_t_ph, train_task_idx),\n",
    "    n_act_dim, q_scope+'-'+str(train_task_idx), \n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation\n",
    "  ), \n",
    "  tf.concat([\n",
    "    demo_batch_idxes, \n",
    "    tf.expand_dims(extract_task(demo_act_t_ph, train_task_idx), 1)], axis=1)\n",
    ") for train_task_idx in range(n_train_tasks)], axis=0)\n",
    "\n",
    "demo_v_t = tf.reduce_logsumexp(\n",
    "  tf.stack([build_mlp(\n",
    "    extract_task(demo_obs_t_ph, train_task_idx),\n",
    "    n_act_dim, q_scope+'-'+str(train_task_idx), \n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation,\n",
    "    reuse=True\n",
    "  ) for train_task_idx in range(n_train_tasks)], axis=0),\n",
    "  axis=2)\n",
    "\n",
    "act_log_likelihoods = demo_q_t - demo_v_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_avg_log_likelihood = -tf.reduce_mean(act_log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_next_obs = build_mlp(\n",
    "  tf.concat((demo_obs_t_ph, demo_act_t_feats_ph), axis=2),\n",
    "  n_obs_dim, invdyn_scope, \n",
    "  n_layers=invdyn_n_layers, size=invdyn_layer_size,\n",
    "  activation=invdyn_activation, output_activation=invdyn_output_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_act_t_feats_reshaped = tf.reshape(\n",
    "  constraint_act_t_feats_ph, [n_train_tasks*constraint_batch_size_ph, n_act_dim])\n",
    "\n",
    "constraint_obs_t_reshaped = tf.reshape(\n",
    "  constraint_obs_t_ph, [n_train_tasks*constraint_batch_size_ph, n_obs_feats])\n",
    "\n",
    "demo_act_t_feats_reshaped = tf.reshape(\n",
    "  demo_act_t_feats_ph, [n_train_tasks*demo_batch_size_ph, n_act_feats])\n",
    "\n",
    "demo_obs_t_reshaped = tf.reshape(\n",
    "  demo_obs_t_ph, [n_train_tasks*demo_batch_size_ph, n_obs_feats])\n",
    "\n",
    "demo_next_obs_t_reshaped = tf.reshape(\n",
    "  demo_next_obs_t_ph, [n_train_tasks, demo_batch_size_ph, n_obs_feats])\n",
    "\n",
    "demo_pred_next_obs_t_reshaped = tf.reshape(\n",
    "    pred_next_obs, [n_train_tasks, demo_batch_size_ph, n_obs_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_err = demo_pred_next_obs_t_reshaped - demo_next_obs_t_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_loss = tf.reduce_mean(trans_err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted constraint next state given inv dyns\n",
    "constraint_obs_tp1 = tf.reshape(build_mlp(\n",
    "  tf.concat((constraint_obs_t_ph, constraint_act_t_feats_ph), axis=2),\n",
    "  n_obs_dim, invdyn_scope, \n",
    "  n_layers=invdyn_n_layers, size=invdyn_layer_size,\n",
    "  activation=invdyn_activation, output_activation=invdyn_output_activation,\n",
    "  reuse=True), [n_train_tasks, constraint_batch_size_ph, n_obs_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_tp1 = tf.stack([build_mlp(\n",
    "    extract_task(constraint_obs_tp1, train_task_idx), \n",
    "    n_act_dim, q_scope+'-'+str(train_task_idx),\n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation, \n",
    "    reuse=True) for train_task_idx in range(n_train_tasks)], axis=0)\n",
    "v_tp1 = tf.reduce_logsumexp(q_tp1, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_t = constraint_rew_t_ph + gamma * v_tp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_batch_idxes = tf.reshape(\n",
    "  tf.range(0, constraint_batch_size_ph, 1), \n",
    "  [constraint_batch_size_ph, 1])\n",
    "\n",
    "# Sampled constraint state q-vals\n",
    "q_t = tf.stack([tf.gather_nd(\n",
    "  build_mlp(\n",
    "    extract_task(constraint_obs_t_ph, train_task_idx), \n",
    "    n_act_dim, q_scope+'-'+str(train_task_idx), \n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation, \n",
    "    reuse=True\n",
    "  ), \n",
    "  tf.concat([\n",
    "    constraint_batch_idxes, \n",
    "    tf.expand_dims(extract_task(constraint_act_t_ph, train_task_idx), 1)], axis=1)\n",
    ") for train_task_idx in range(n_train_tasks)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bellman errors\n",
    "td_err = q_t - target_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_td_err = tf.reduce_mean(td_err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = neg_avg_log_likelihood + sq_td_err_penalty * sq_td_err + trans_err_penalty * trans_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_update_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "trans_update_op = tf.train.AdamOptimizer(learning_rate).minimize(trans_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_constraints(_):\n",
    "  constraint_rollouts = [[] for _ in range(n_train_tasks)]\n",
    "  \n",
    "  for train_task_idx in range(n_train_tasks):\n",
    "    rollouts = [[] for _ in range(n_constraint_rollouts_per_env)]\n",
    "    envs = [make_lander_env(\n",
    "      fps=fps, goal=train_goals[train_task_idx]) for _ in range(\n",
    "      n_constraint_rollouts_per_env)]\n",
    "    obses = np.array([env.reset() for env in envs])\n",
    "    dones = [False for _ in envs]\n",
    "    prev_obses = obses\n",
    "    for step_idx in range(max_ep_len+1):\n",
    "      not_done_idxes = [i for i, done in enumerate(dones) if not done]\n",
    "      batch_size = len(not_done_idxes)\n",
    "      if batch_size == 0:\n",
    "        break\n",
    "      actions = np.random.choice(n_act_dim, batch_size)\n",
    "      for i, env_idx in enumerate(not_done_idxes):\n",
    "        env = envs[env_idx]\n",
    "        action = actions[i]\n",
    "        obs, r, done, info = env.step(action)\n",
    "        obses[env_idx] = obs\n",
    "        dones[env_idx] = done\n",
    "        rollouts[env_idx].append((\n",
    "          prev_obses[env_idx], action, r))\n",
    "      prev_obses = copy(obses)\n",
    "    constraint_rollouts[train_task_idx].extend([r for r in rollouts if r != []])\n",
    "\n",
    "  size = min(sum(len(r) for r in rollouts) for rollouts in constraint_rollouts)\n",
    "  \n",
    "  global train_constraint_example_idxes\n",
    "  global val_constraint_batch\n",
    "  global constraint_obs_t\n",
    "  global constraint_act_t\n",
    "  global constraint_rew_t\n",
    "  global constraint_act_t_feats\n",
    "    \n",
    "  constraint_obs_t = np.zeros((n_train_tasks, size, n_obs_feats))\n",
    "  constraint_act_t = np.zeros((n_train_tasks, size))\n",
    "  constraint_act_t_feats = np.zeros((n_train_tasks, size, n_act_feats))\n",
    "  constraint_rew_t = np.zeros((n_train_tasks, size))\n",
    "  \n",
    "  for train_task_idx in range(n_train_tasks):\n",
    "    unfeat_obses, actions, rews = list(zip(*sum(\n",
    "      constraint_rollouts[train_task_idx], [])))\n",
    "    obses = [featurize_obs(s) for s in unfeat_obses]\n",
    "    act_feats = [disc_to_cont(a) for a in actions]\n",
    "    idxes = random.sample(list(range(len(obses))), size)\n",
    "    constraint_obs_t[train_task_idx, :, :] = np.array(obses)[idxes, :]\n",
    "    constraint_act_t[train_task_idx, :] = np.array(actions)[idxes]\n",
    "    constraint_rew_t[train_task_idx, :] = np.array(rews)[idxes]\n",
    "    constraint_act_t_feats[train_task_idx, :, :] = np.array(act_feats)[idxes, :]\n",
    "\n",
    "  \n",
    "  constraint_example_idxes = list(range(size))\n",
    "  random.shuffle(constraint_example_idxes)\n",
    "  n_train_constraint_examples = int(0.9 * size)\n",
    "  \n",
    "  train_constraint_example_idxes = constraint_example_idxes[:n_train_constraint_examples]\n",
    "  val_constraint_example_idxes = constraint_example_idxes[n_train_constraint_examples:]\n",
    "  val_constraint_batch = (constraint_obs_t[:, val_constraint_example_idxes],\n",
    "                          constraint_act_t[:, val_constraint_example_idxes],\n",
    "                          constraint_act_t_feats[:, val_constraint_example_idxes],\n",
    "                          constraint_rew_t[:, val_constraint_example_idxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_constraint_batch(size):\n",
    "  global n_iters_since_prev_constraint_sample\n",
    "  if n_iters_since_prev_constraint_sample % constraint_sampling_freq == 0:\n",
    "    sample_constraints(size)\n",
    "    n_iters_since_prev_constraint_sample = 0\n",
    "  n_iters_since_prev_constraint_sample += 1\n",
    "\n",
    "  idxes = random.sample(train_constraint_example_idxes, size)\n",
    "  constraint_batch = (constraint_obs_t[:, idxes],\n",
    "    constraint_act_t[:, idxes],\n",
    "    constraint_act_t_feats[:, idxes],\n",
    "    constraint_rew_t[:, idxes])\n",
    "  return constraint_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_constraint_example_idxes = None\n",
    "val_constraint_batch = None\n",
    "constraint_obs_t = None\n",
    "constraint_act_t = None\n",
    "constraint_act_t_feats = None\n",
    "constraint_rew_t = None\n",
    "n_iters_since_prev_constraint_sample = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'constraint_samples.pkl'), 'wb') as f:\n",
    "  pickle.dump((\n",
    "    train_constraint_example_idxes, \n",
    "    val_constraint_batch,\n",
    "    constraint_obs_t,\n",
    "    constraint_act_t,\n",
    "    constraint_act_t_feats,\n",
    "    constraint_rew_t,\n",
    "    n_iters_since_prev_constraint_sample), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'constraint_samples.pkl'), 'rb') as f:\n",
    "  (train_constraint_example_idxes, \n",
    "    val_constraint_batch,\n",
    "    constraint_obs_t,\n",
    "    constraint_act_t,\n",
    "    constraint_act_t_feats,\n",
    "    constraint_rew_t,\n",
    "    n_iters_since_prev_constraint_sample) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iters = iterations * demo_obs.shape[1] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_loss(demo_batch, constraint_batch, step=False, trans_only=False, t=None):\n",
    "  demo_batch_obs_t, demo_batch_act_t, demo_batch_act_t_feats, demo_batch_next_obs_t = demo_batch\n",
    "  constraint_batch_obs_t, constraint_batch_act_t, constraint_batch_act_t_feats, constraint_batch_rew_t = constraint_batch\n",
    "\n",
    "  feed_dict = {\n",
    "    demo_obs_t_ph: demo_batch_obs_t,\n",
    "    demo_act_t_ph: demo_batch_act_t,\n",
    "    demo_act_t_feats_ph: demo_batch_act_t_feats,\n",
    "    demo_next_obs_t_ph: demo_batch_next_obs_t,\n",
    "    demo_batch_size_ph: demo_batch_obs_t.shape[1],\n",
    "    constraint_obs_t_ph: constraint_batch_obs_t,\n",
    "    constraint_act_t_ph: constraint_batch_act_t,\n",
    "    constraint_act_t_feats_ph: constraint_batch_act_t_feats,\n",
    "    constraint_rew_t_ph: constraint_batch_rew_t,\n",
    "    constraint_batch_size_ph: constraint_batch_obs_t.shape[1],\n",
    "  }\n",
    "  \n",
    "  if trans_only:\n",
    "    [loss_eval] = sess.run([trans_loss], feed_dict=feed_dict)\n",
    "    update_op = trans_update_op\n",
    "    d = {\n",
    "    'loss': loss_eval,\n",
    "      }\n",
    "  else:\n",
    "    [loss_eval, neg_avg_log_likelihood_eval, sq_td_err_eval, trans_loss_eval] = sess.run(\n",
    "        [loss, neg_avg_log_likelihood, sq_td_err, trans_loss], feed_dict=feed_dict)\n",
    "    update_op = full_update_op\n",
    "    d = {\n",
    "        'loss': loss_eval,\n",
    "        'nll': neg_avg_log_likelihood_eval,\n",
    "        'ste': sq_td_err_eval,\n",
    "        'tl': trans_loss_eval\n",
    "      }\n",
    "  \n",
    "  if step:\n",
    "    sess.run(update_op, feed_dict=feed_dict)\n",
    "#   else:\n",
    "#     d.update(compute_int_dyn_nll())\n",
    "    \n",
    "  return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Dynamics with Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_logs = {\n",
    "  'loss_evals': [],\n",
    "  'tl_evals': [],\n",
    "  'nll_evals': [],\n",
    "  'ste_evals': [],\n",
    "  'val_loss_evals': [],\n",
    "  'val_tl_evals': [],\n",
    "  'val_nll_evals': [],\n",
    "  'val_ste_evals': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_log = None\n",
    "while len(full_train_logs['loss_evals']) < n_iters:\n",
    "  demo_batch = sample_batch(batch_size)\n",
    "  constraint_batch = sample_constraint_batch(constraint_batch_size)\n",
    "  t = len(full_train_logs['loss_evals'])\n",
    "  train_log = compute_batch_loss(demo_batch, constraint_batch, step=True, t=t)\n",
    "  if val_log is None or len(full_train_logs['loss_evals']) % val_update_freq == 0:\n",
    "    val_log = compute_batch_loss(val_demo_batch, val_constraint_batch, step=False, t=t)\n",
    "  \n",
    "  if len(full_train_logs['loss_evals']) % 1000 == 0:\n",
    "      print('%d %d %f %f %f %f' % (\n",
    "        t, n_iters, train_log['loss'], train_log['tl'], val_log['loss'], val_log['tl'])\n",
    "      )\n",
    "  for k, v in train_log.items():\n",
    "    full_train_logs['%s_evals' % k].append(v)\n",
    "  for k, v in val_log.items():\n",
    "    full_train_logs['%s%s_evals' % ('val_' if k in ['loss', 'nll', 'ste', 'tl'] else '', k)].append(v)\n",
    "  if len(full_train_logs['loss_evals']) % 10000 == 0:\n",
    "    for k in ['val_nll_evals', 'val_ste_evals']:\n",
    "      plt.xlabel('Iterations')\n",
    "      plt.ylabel(k.split('_')[1])\n",
    "      plt.plot(full_train_logs[k])\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in ['val_nll_evals', 'val_ste_evals']:\n",
    "  plt.xlabel('Iterations')\n",
    "  plt.ylabel(k.split('_')[1])\n",
    "  plt.plot(full_train_logs[k])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Negative Log-Likelihood')\n",
    "plt.plot(train_logs['int_dyn_nll_evals'], color='orange')\n",
    "# plt.axhline(y=-np.log(1/n_ims), linestyle='--', color='gray', label='Uniform')\n",
    "plt.ylim([-0.05, None])\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'qt_results.pkl'), 'wb') as f:\n",
    "  pickle.dump(full_train_logs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Dynamics Without Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_constraint_example_idxes = None\n",
    "val_constraint_batch = None\n",
    "constraint_obs_t = None\n",
    "constraint_act_t = None\n",
    "constraint_act_t_feats = None\n",
    "n_iters_since_prev_constraint_sample = 0\n",
    "\n",
    "tf.global_variables_initializer().run(session=sess)\n",
    "\n",
    "n_iters = iterations * demo_obs.shape[1] // batch_size\n",
    "\n",
    "trans_train_logs = {\n",
    "  'loss_evals': [],\n",
    "  'nll_evals': [],\n",
    "  'ste_evals': [],\n",
    "  'val_loss_evals': [],\n",
    "  'val_nll_evals': [],\n",
    "  'val_ste_evals': [],\n",
    "  'int_dyn_err_evals': []\n",
    "}\n",
    "val_log = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(trans_train_logs['loss_evals']) < n_iters:\n",
    "  demo_batch = sample_batch(batch_size)\n",
    "  constraint_batch = sample_constraint_batch(constraint_batch_size)\n",
    "  \n",
    "  t = len(trans_train_logs['loss_evals'])\n",
    "  train_log = compute_batch_loss(demo_batch, constraint_batch, trans_only=True, step=True, t=t)\n",
    "  if val_log is None or len(trans_train_logs['loss_evals']) % val_update_freq == 0:\n",
    "    val_log = compute_batch_loss(val_demo_batch, val_constraint_batch, trans_only=True, step=False, t=t)\n",
    "  \n",
    "  if len(trans_train_logs['loss_evals']) % 1000 == 0:\n",
    "      print('%d %d %f %f' % (\n",
    "        t, n_iters, train_log['loss'], val_log['loss'],)\n",
    "      )\n",
    "\n",
    "  trans_train_logs['loss_evals'].append(train_log['loss'])\n",
    "  trans_train_logs['val_loss_evals'].append(val_log['loss'])\n",
    "  if len(trans_train_logs['loss_evals']) % 10000 == 0:\n",
    "    for k in ['loss_evals', 'val_loss_evals']:\n",
    "      plt.xlabel('Iterations')\n",
    "      plt.ylabel(k.split('_')[1])\n",
    "      plt.plot(trans_train_logs[k])\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
